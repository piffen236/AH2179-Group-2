{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b3ff328c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3ff328c",
        "outputId": "3110b370-5e45-4b22-b09a-b7a10b87cc7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting calplot\n",
            "  Downloading calplot-0.1.7.5.tar.gz (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from calplot) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from calplot) (1.23.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->calplot) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->calplot) (0.12.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->calplot) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->calplot) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->calplot) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->calplot) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->calplot) (3.1.1)\n",
            "Building wheels for collected packages: calplot\n",
            "  Building wheel for calplot (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for calplot: filename=calplot-0.1.7.5-py3-none-any.whl size=8115 sha256=1cc3a52bef9b4ef2beff495d5dbca47dbe8440ad23268b5ad0e424937f069b69\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/75/32/a518a4a1421776a93e1ede33cb8dac474095bf31fed7e4e22c\n",
            "Successfully built calplot\n",
            "Installing collected packages: calplot\n",
            "Successfully installed calplot-0.1.7.5\n"
          ]
        }
      ],
      "source": [
        "!pip install calplot pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "619525a5",
      "metadata": {
        "id": "619525a5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "#Plot\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "import seaborn as sns\n",
        "import calendar\n",
        "import calplot # actually used\n",
        "\n",
        "# Score model\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Ridge, LinearRegression\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "04a64600",
      "metadata": {
        "id": "04a64600"
      },
      "outputs": [],
      "source": [
        "url = \"https://raw.githubusercontent.com/zhenliangma/Applied-AI-in-Transportation/main/ProjectAssignmentData/Dataset-PT.csv\"\n",
        "df = pd.read_csv(url,header=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6b091cb5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "6b091cb5",
        "outputId": "49d1bb19-c930-4c26-f0f6-d91731d43c75"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Calendar_date  route_id  bus_id  stop_sequence  arrival_delay  dwell_time  \\\n",
              "0       20220108         4   41344              1            151           0   \n",
              "1       20220108         4   41344              2            185          24   \n",
              "2       20220108         4   41344              3            186           0   \n",
              "3       20220108         4   41344              4            202          12   \n",
              "4       20220108         4   41344              5            242          21   \n",
              "\n",
              "   travel_time_for_previous_section  scheduled_travel_time  \\\n",
              "0                                 0                    120   \n",
              "1                               171                     45   \n",
              "2                                55                     41   \n",
              "3                                42                     94   \n",
              "4                                98                     86   \n",
              "\n",
              "   upstream_stop_delay  origin_delay  ...  factor(weather)Rain  \\\n",
              "0                  100           100  ...                    0   \n",
              "1                  151           100  ...                    0   \n",
              "2                  185           100  ...                    0   \n",
              "3                  186           100  ...                    0   \n",
              "4                  202           100  ...                    0   \n",
              "\n",
              "   factor(weather)Snow  factor(temperature)Cold  \\\n",
              "0                    0                        0   \n",
              "1                    0                        0   \n",
              "2                    0                        0   \n",
              "3                    0                        0   \n",
              "4                    0                        0   \n",
              "\n",
              "   factor(temperature)Extra_cold factor(temperature)Normal  \\\n",
              "0                              0                         1   \n",
              "1                              0                         1   \n",
              "2                              0                         1   \n",
              "3                              0                         1   \n",
              "4                              0                         1   \n",
              "\n",
              "  factor(day_of_week)weekday factor(day_of_week)weekend  \\\n",
              "0                          0                          1   \n",
              "1                          0                          1   \n",
              "2                          0                          1   \n",
              "3                          0                          1   \n",
              "4                          0                          1   \n",
              "\n",
              "  factor(time_of_day)Afternoon_peak  factor(time_of_day)Morning_peak  \\\n",
              "0                                 0                                0   \n",
              "1                                 0                                0   \n",
              "2                                 0                                0   \n",
              "3                                 0                                0   \n",
              "4                                 0                                0   \n",
              "\n",
              "   factor(time_of_day)Off-peak  \n",
              "0                            1  \n",
              "1                            1  \n",
              "2                            1  \n",
              "3                            1  \n",
              "4                            1  \n",
              "\n",
              "[5 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-638f01ff-f547-453a-85ce-4d5948123073\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Calendar_date</th>\n",
              "      <th>route_id</th>\n",
              "      <th>bus_id</th>\n",
              "      <th>stop_sequence</th>\n",
              "      <th>arrival_delay</th>\n",
              "      <th>dwell_time</th>\n",
              "      <th>travel_time_for_previous_section</th>\n",
              "      <th>scheduled_travel_time</th>\n",
              "      <th>upstream_stop_delay</th>\n",
              "      <th>origin_delay</th>\n",
              "      <th>...</th>\n",
              "      <th>factor(weather)Rain</th>\n",
              "      <th>factor(weather)Snow</th>\n",
              "      <th>factor(temperature)Cold</th>\n",
              "      <th>factor(temperature)Extra_cold</th>\n",
              "      <th>factor(temperature)Normal</th>\n",
              "      <th>factor(day_of_week)weekday</th>\n",
              "      <th>factor(day_of_week)weekend</th>\n",
              "      <th>factor(time_of_day)Afternoon_peak</th>\n",
              "      <th>factor(time_of_day)Morning_peak</th>\n",
              "      <th>factor(time_of_day)Off-peak</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20220108</td>\n",
              "      <td>4</td>\n",
              "      <td>41344</td>\n",
              "      <td>1</td>\n",
              "      <td>151</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20220108</td>\n",
              "      <td>4</td>\n",
              "      <td>41344</td>\n",
              "      <td>2</td>\n",
              "      <td>185</td>\n",
              "      <td>24</td>\n",
              "      <td>171</td>\n",
              "      <td>45</td>\n",
              "      <td>151</td>\n",
              "      <td>100</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20220108</td>\n",
              "      <td>4</td>\n",
              "      <td>41344</td>\n",
              "      <td>3</td>\n",
              "      <td>186</td>\n",
              "      <td>0</td>\n",
              "      <td>55</td>\n",
              "      <td>41</td>\n",
              "      <td>185</td>\n",
              "      <td>100</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20220108</td>\n",
              "      <td>4</td>\n",
              "      <td>41344</td>\n",
              "      <td>4</td>\n",
              "      <td>202</td>\n",
              "      <td>12</td>\n",
              "      <td>42</td>\n",
              "      <td>94</td>\n",
              "      <td>186</td>\n",
              "      <td>100</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20220108</td>\n",
              "      <td>4</td>\n",
              "      <td>41344</td>\n",
              "      <td>5</td>\n",
              "      <td>242</td>\n",
              "      <td>21</td>\n",
              "      <td>98</td>\n",
              "      <td>86</td>\n",
              "      <td>202</td>\n",
              "      <td>100</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-638f01ff-f547-453a-85ce-4d5948123073')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-638f01ff-f547-453a-85ce-4d5948123073 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-638f01ff-f547-453a-85ce-4d5948123073');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-98cef105-ebf8-4f7c-a90b-f7441fb769f9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-98cef105-ebf8-4f7c-a90b-f7441fb769f9')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-98cef105-ebf8-4f7c-a90b-f7441fb769f9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df.head(5)\n",
        "# df.size 545104 rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a76c1d26",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a76c1d26",
        "outputId": "fb2ec279-a1f1-4e3e-e7e9-b56da376873d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of outliers removed: 228\n",
            "Size of the original DataFrame: 545103\n",
            "Size of the DataFrame after removing outliers: 544875\n"
          ]
        }
      ],
      "source": [
        "from scipy import stats\n",
        "\n",
        "# Calculate z-scores for the 'arrival_delay' column\n",
        "z_scores = stats.zscore(df['arrival_delay'])\n",
        "\n",
        "# Get boolean array indicating the location of outliers\n",
        "outliers = (z_scores > 7) | (z_scores < -7)\n",
        "\n",
        "# Count the number of outliers\n",
        "num_outliers = outliers.sum()\n",
        "\n",
        "# Print the number of outliers\n",
        "print(f\"Number of outliers removed: {num_outliers}\")\n",
        "\n",
        "# Remove the outliers\n",
        "df_no_outliers = df[~outliers]\n",
        "\n",
        "# Verify the new size of the DataFrame\n",
        "print(f\"Size of the original DataFrame: {len(df)}\")\n",
        "print(f\"Size of the DataFrame after removing outliers: {len(df_no_outliers)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df_no_outliers"
      ],
      "metadata": {
        "id": "HCvmTMm1jiC6"
      },
      "id": "HCvmTMm1jiC6",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "LBs3sZh86PPC",
      "metadata": {
        "id": "LBs3sZh86PPC"
      },
      "source": [
        "# Model without weather"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "desired_stop_sequences = [1, 5, 8, 12, 14, 16, 20, 21, 23]\n",
        "\n",
        "# desired_stop_sequences = [1, 5]  # In case to verify the codes\n",
        "\n",
        "# Create a boolean mask for rows with the desired stop sequence\n",
        "mask = df_no_outliers['stop_sequence'].isin(desired_stop_sequences)\n",
        "\n",
        "# Filter the DataFrame to keep only the rows with the desired stop sequence\n",
        "df_selected_stops = df_no_outliers[mask]\n",
        "\n",
        "df_selected_stops.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQwi7CFlERr6",
        "outputId": "4aa92fe1-e823-4a06-b323-21a9d74cf194"
      },
      "id": "bQwi7CFlERr6",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(181626, 31)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_9stops = df_selected_stops.drop(['Calendar_date','route_id', 'bus_id'], axis = 1)\n",
        "columns_to_drop = [\n",
        "    'weather', 'temperature', 'time_of_day',\n",
        "    'factor(weather)Light_Rain', 'factor(weather)Light_Snow',\n",
        "    'factor(weather)Normal', 'factor(weather)Rain', 'factor(weather)Snow',\n",
        "    'factor(temperature)Cold', 'factor(temperature)Extra_cold',\n",
        "    'factor(temperature)Normal', 'factor(day_of_week)weekday',\n",
        "    'factor(day_of_week)weekend', 'factor(time_of_day)Afternoon_peak',\n",
        "    'factor(time_of_day)Morning_peak', 'factor(time_of_day)Off-peak'\n",
        "]\n",
        "for column in columns_to_drop:\n",
        "    df_9stops.pop(column)"
      ],
      "metadata": {
        "id": "mKc-1ALXGZ40"
      },
      "id": "mKc-1ALXGZ40",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_9stops.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nzmmA_rGel2",
        "outputId": "2bf5a8b4-ebcd-48b4-fe87-559f222e9e84"
      },
      "id": "-nzmmA_rGel2",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 181626 entries, 0 to 545098\n",
            "Data columns (total 12 columns):\n",
            " #   Column                            Non-Null Count   Dtype  \n",
            "---  ------                            --------------   -----  \n",
            " 0   stop_sequence                     181626 non-null  int64  \n",
            " 1   arrival_delay                     181626 non-null  int64  \n",
            " 2   dwell_time                        181626 non-null  int64  \n",
            " 3   travel_time_for_previous_section  181626 non-null  int64  \n",
            " 4   scheduled_travel_time             181626 non-null  int64  \n",
            " 5   upstream_stop_delay               181626 non-null  int64  \n",
            " 6   origin_delay                      181626 non-null  int64  \n",
            " 7   previous_bus_delay                181626 non-null  int64  \n",
            " 8   previous_trip_travel_time         181626 non-null  int64  \n",
            " 9   traffic_condition                 181626 non-null  float64\n",
            " 10  recurrent_delay                   181626 non-null  float64\n",
            " 11  day_of_week                       181626 non-null  object \n",
            "dtypes: float64(2), int64(9), object(1)\n",
            "memory usage: 18.0+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bd697ca",
      "metadata": {
        "id": "4bd697ca"
      },
      "source": [
        "### Neural Network Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "898CZJgs6RYT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "898CZJgs6RYT",
        "outputId": "fa286ba1-fb7f-4b62-c947-830eb8590c0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "309/309 [==============================] - 2s 3ms/step - loss: 47.8543 - mae: 47.8543 - val_loss: 27.6448 - val_mae: 27.6448\n",
            "Epoch 2/100\n",
            "309/309 [==============================] - 1s 4ms/step - loss: 27.3806 - mae: 27.3806 - val_loss: 27.5837 - val_mae: 27.5837\n",
            "Epoch 3/100\n",
            "309/309 [==============================] - 1s 5ms/step - loss: 27.3942 - mae: 27.3942 - val_loss: 27.6158 - val_mae: 27.6158\n",
            "Epoch 4/100\n",
            "309/309 [==============================] - 1s 3ms/step - loss: 27.3734 - mae: 27.3734 - val_loss: 27.6253 - val_mae: 27.6253\n",
            "Epoch 5/100\n",
            "309/309 [==============================] - 1s 3ms/step - loss: 27.4083 - mae: 27.4083 - val_loss: 27.8424 - val_mae: 27.8424\n",
            "Epoch 6/100\n",
            "309/309 [==============================] - 1s 2ms/step - loss: 27.3820 - mae: 27.3820 - val_loss: 27.6290 - val_mae: 27.6290\n",
            "Epoch 7/100\n",
            "309/309 [==============================] - 1s 3ms/step - loss: 27.3341 - mae: 27.3341 - val_loss: 27.5494 - val_mae: 27.5494\n",
            "Epoch 8/100\n",
            "309/309 [==============================] - 1s 3ms/step - loss: 27.4127 - mae: 27.4127 - val_loss: 27.7193 - val_mae: 27.7193\n",
            "Epoch 9/100\n",
            "309/309 [==============================] - 1s 2ms/step - loss: 27.3813 - mae: 27.3813 - val_loss: 27.5733 - val_mae: 27.5733\n",
            "Epoch 10/100\n",
            "309/309 [==============================] - 1s 2ms/step - loss: 27.3341 - mae: 27.3341 - val_loss: 27.5075 - val_mae: 27.5075\n",
            "Epoch 11/100\n",
            "309/309 [==============================] - 1s 2ms/step - loss: 27.3492 - mae: 27.3492 - val_loss: 27.5578 - val_mae: 27.5578\n",
            "Epoch 12/100\n",
            "309/309 [==============================] - 1s 2ms/step - loss: 27.3875 - mae: 27.3875 - val_loss: 27.6172 - val_mae: 27.6172\n",
            "Epoch 13/100\n",
            "309/309 [==============================] - 1s 3ms/step - loss: 27.3734 - mae: 27.3734 - val_loss: 27.7976 - val_mae: 27.7976\n",
            "Epoch 14/100\n",
            "309/309 [==============================] - 1s 3ms/step - loss: 27.3868 - mae: 27.3868 - val_loss: 27.5865 - val_mae: 27.5865\n",
            "Epoch 15/100\n",
            "309/309 [==============================] - 1s 3ms/step - loss: 27.3433 - mae: 27.3433 - val_loss: 27.8369 - val_mae: 27.8369\n",
            "Epoch 16/100\n",
            "309/309 [==============================] - 1s 3ms/step - loss: 27.3556 - mae: 27.3556 - val_loss: 27.5704 - val_mae: 27.5704\n",
            "Epoch 17/100\n",
            "309/309 [==============================] - 1s 4ms/step - loss: 27.3510 - mae: 27.3510 - val_loss: 27.5525 - val_mae: 27.5525\n",
            "Epoch 18/100\n",
            "309/309 [==============================] - 1s 4ms/step - loss: 27.3423 - mae: 27.3423 - val_loss: 27.5676 - val_mae: 27.5676\n",
            "Epoch 19/100\n",
            "309/309 [==============================] - 1s 3ms/step - loss: 27.3610 - mae: 27.3610 - val_loss: 27.5440 - val_mae: 27.5440\n",
            "Epoch 20/100\n",
            "309/309 [==============================] - 1s 3ms/step - loss: 27.3551 - mae: 27.3551 - val_loss: 27.6085 - val_mae: 27.6085\n",
            "99/99 [==============================] - 0s 1ms/step\n",
            "Epoch 1/100\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 117.6880 - mae: 117.6880 - val_loss: 119.2428 - val_mae: 119.2428\n",
            "Epoch 2/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 93.8426 - mae: 93.8426 - val_loss: 72.4719 - val_mae: 72.4719\n",
            "Epoch 3/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 37.5696 - mae: 37.5696 - val_loss: 27.1627 - val_mae: 27.1627\n",
            "Epoch 4/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 26.5711 - mae: 26.5711 - val_loss: 27.1864 - val_mae: 27.1864\n",
            "Epoch 5/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 26.3462 - mae: 26.3462 - val_loss: 27.3499 - val_mae: 27.3499\n",
            "Epoch 6/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 26.3501 - mae: 26.3501 - val_loss: 27.1178 - val_mae: 27.1178\n",
            "Epoch 7/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 26.2310 - mae: 26.2310 - val_loss: 27.0035 - val_mae: 27.0035\n",
            "Epoch 8/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 26.1644 - mae: 26.1644 - val_loss: 26.9534 - val_mae: 26.9534\n",
            "Epoch 9/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 26.1066 - mae: 26.1066 - val_loss: 27.3332 - val_mae: 27.3332\n",
            "Epoch 10/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 26.0774 - mae: 26.0774 - val_loss: 26.9948 - val_mae: 26.9948\n",
            "Epoch 11/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 26.0664 - mae: 26.0664 - val_loss: 26.9431 - val_mae: 26.9431\n",
            "Epoch 12/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 26.0328 - mae: 26.0328 - val_loss: 26.9992 - val_mae: 26.9992\n",
            "Epoch 13/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 25.9393 - mae: 25.9393 - val_loss: 27.1085 - val_mae: 27.1085\n",
            "Epoch 14/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 25.9896 - mae: 25.9896 - val_loss: 27.1034 - val_mae: 27.1034\n",
            "Epoch 15/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 25.8528 - mae: 25.8528 - val_loss: 27.0173 - val_mae: 27.0173\n",
            "Epoch 16/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 25.9756 - mae: 25.9756 - val_loss: 27.0490 - val_mae: 27.0490\n",
            "Epoch 17/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 25.9876 - mae: 25.9876 - val_loss: 27.0095 - val_mae: 27.0095\n",
            "Epoch 18/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 25.9368 - mae: 25.9368 - val_loss: 26.9220 - val_mae: 26.9220\n",
            "Epoch 19/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 25.9861 - mae: 25.9861 - val_loss: 26.9652 - val_mae: 26.9652\n",
            "Epoch 20/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 25.9848 - mae: 25.9848 - val_loss: 27.2707 - val_mae: 27.2707\n",
            "Epoch 21/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 25.9153 - mae: 25.9153 - val_loss: 26.8043 - val_mae: 26.8043\n",
            "Epoch 22/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 26.0130 - mae: 26.0130 - val_loss: 26.9215 - val_mae: 26.9215\n",
            "Epoch 23/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 25.9230 - mae: 25.9230 - val_loss: 27.1932 - val_mae: 27.1932\n",
            "Epoch 24/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 25.9891 - mae: 25.9891 - val_loss: 26.9633 - val_mae: 26.9633\n",
            "Epoch 25/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 25.8879 - mae: 25.8879 - val_loss: 27.0676 - val_mae: 27.0676\n",
            "Epoch 26/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 25.9650 - mae: 25.9650 - val_loss: 26.9324 - val_mae: 26.9324\n",
            "Epoch 27/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 25.8168 - mae: 25.8168 - val_loss: 27.0346 - val_mae: 27.0346\n",
            "Epoch 28/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 25.8935 - mae: 25.8935 - val_loss: 26.9502 - val_mae: 26.9502\n",
            "Epoch 29/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 25.9258 - mae: 25.9258 - val_loss: 26.9701 - val_mae: 26.9701\n",
            "Epoch 30/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 25.9503 - mae: 25.9503 - val_loss: 26.8838 - val_mae: 26.8838\n",
            "Epoch 31/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 25.9103 - mae: 25.9103 - val_loss: 26.9431 - val_mae: 26.9431\n",
            "30/30 [==============================] - 0s 1ms/step\n",
            "Epoch 1/100\n",
            "312/312 [==============================] - 2s 3ms/step - loss: 64.2993 - mae: 64.2993 - val_loss: 19.2756 - val_mae: 19.2756\n",
            "Epoch 2/100\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 15.6624 - mae: 15.6624 - val_loss: 14.4407 - val_mae: 14.4407\n",
            "Epoch 3/100\n",
            "312/312 [==============================] - 1s 2ms/step - loss: 14.3912 - mae: 14.3912 - val_loss: 14.3136 - val_mae: 14.3136\n",
            "Epoch 4/100\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 14.3631 - mae: 14.3631 - val_loss: 14.2210 - val_mae: 14.2210\n",
            "Epoch 5/100\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 14.3942 - mae: 14.3942 - val_loss: 14.3535 - val_mae: 14.3535\n",
            "Epoch 6/100\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 14.3452 - mae: 14.3452 - val_loss: 14.3629 - val_mae: 14.3629\n",
            "Epoch 7/100\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 14.3498 - mae: 14.3498 - val_loss: 14.3696 - val_mae: 14.3696\n",
            "Epoch 8/100\n",
            "312/312 [==============================] - 1s 2ms/step - loss: 14.3613 - mae: 14.3613 - val_loss: 14.2526 - val_mae: 14.2526\n",
            "Epoch 9/100\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 14.3734 - mae: 14.3734 - val_loss: 14.2613 - val_mae: 14.2613\n",
            "Epoch 10/100\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 14.3432 - mae: 14.3432 - val_loss: 14.3435 - val_mae: 14.3435\n",
            "Epoch 11/100\n",
            "312/312 [==============================] - 1s 4ms/step - loss: 14.3883 - mae: 14.3883 - val_loss: 14.3075 - val_mae: 14.3075\n",
            "Epoch 12/100\n",
            "312/312 [==============================] - 1s 4ms/step - loss: 14.3237 - mae: 14.3237 - val_loss: 14.2580 - val_mae: 14.2580\n",
            "Epoch 13/100\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 14.3369 - mae: 14.3369 - val_loss: 14.2537 - val_mae: 14.2537\n",
            "Epoch 14/100\n",
            "312/312 [==============================] - 1s 2ms/step - loss: 14.3550 - mae: 14.3550 - val_loss: 14.3610 - val_mae: 14.3610\n",
            "95/95 [==============================] - 0s 1ms/step\n",
            "Epoch 1/100\n",
            "94/94 [==============================] - 2s 7ms/step - loss: 156.9922 - mae: 156.9922 - val_loss: 138.1611 - val_mae: 138.1611\n",
            "Epoch 2/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 138.0052 - mae: 138.0052 - val_loss: 99.5047 - val_mae: 99.5047\n",
            "Epoch 3/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 55.4170 - mae: 55.4170 - val_loss: 21.5245 - val_mae: 21.5245\n",
            "Epoch 4/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 18.7977 - mae: 18.7977 - val_loss: 16.4659 - val_mae: 16.4659\n",
            "Epoch 5/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 15.0903 - mae: 15.0903 - val_loss: 13.2230 - val_mae: 13.2230\n",
            "Epoch 6/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 12.8413 - mae: 12.8413 - val_loss: 12.0592 - val_mae: 12.0592\n",
            "Epoch 7/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 11.9326 - mae: 11.9326 - val_loss: 11.8586 - val_mae: 11.8586\n",
            "Epoch 8/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 11.7724 - mae: 11.7724 - val_loss: 11.5179 - val_mae: 11.5179\n",
            "Epoch 9/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 11.7403 - mae: 11.7403 - val_loss: 11.8134 - val_mae: 11.8134\n",
            "Epoch 10/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 11.7062 - mae: 11.7062 - val_loss: 11.7938 - val_mae: 11.7938\n",
            "Epoch 11/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 11.6070 - mae: 11.6070 - val_loss: 11.6112 - val_mae: 11.6112\n",
            "Epoch 12/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 11.7455 - mae: 11.7455 - val_loss: 11.8889 - val_mae: 11.8889\n",
            "Epoch 13/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 11.7924 - mae: 11.7924 - val_loss: 11.6606 - val_mae: 11.6606\n",
            "Epoch 14/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 11.7616 - mae: 11.7616 - val_loss: 11.9132 - val_mae: 11.9132\n",
            "Epoch 15/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 11.6385 - mae: 11.6385 - val_loss: 11.6429 - val_mae: 11.6429\n",
            "Epoch 16/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 11.6716 - mae: 11.6716 - val_loss: 11.7704 - val_mae: 11.7704\n",
            "Epoch 17/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 11.6660 - mae: 11.6660 - val_loss: 11.6966 - val_mae: 11.6966\n",
            "Epoch 18/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 11.7198 - mae: 11.7198 - val_loss: 11.6148 - val_mae: 11.6148\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "Epoch 1/100\n",
            "310/310 [==============================] - 2s 3ms/step - loss: 72.4959 - mae: 72.4959 - val_loss: 26.5368 - val_mae: 26.5368\n",
            "Epoch 2/100\n",
            "310/310 [==============================] - 1s 3ms/step - loss: 19.4974 - mae: 19.4974 - val_loss: 16.1229 - val_mae: 16.1229\n",
            "Epoch 3/100\n",
            "310/310 [==============================] - 1s 2ms/step - loss: 16.2121 - mae: 16.2121 - val_loss: 15.9299 - val_mae: 15.9299\n",
            "Epoch 4/100\n",
            "310/310 [==============================] - 1s 3ms/step - loss: 16.2032 - mae: 16.2032 - val_loss: 16.0980 - val_mae: 16.0980\n",
            "Epoch 5/100\n",
            "310/310 [==============================] - 1s 3ms/step - loss: 16.2393 - mae: 16.2393 - val_loss: 16.0623 - val_mae: 16.0623\n",
            "Epoch 6/100\n",
            "310/310 [==============================] - 1s 3ms/step - loss: 16.2648 - mae: 16.2648 - val_loss: 16.0180 - val_mae: 16.0180\n",
            "Epoch 7/100\n",
            "310/310 [==============================] - 1s 5ms/step - loss: 16.2545 - mae: 16.2545 - val_loss: 16.1397 - val_mae: 16.1397\n",
            "Epoch 8/100\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 16.2390 - mae: 16.2390 - val_loss: 15.9608 - val_mae: 15.9608\n",
            "Epoch 9/100\n",
            "310/310 [==============================] - 1s 3ms/step - loss: 16.2265 - mae: 16.2265 - val_loss: 16.0754 - val_mae: 16.0754\n",
            "Epoch 10/100\n",
            "310/310 [==============================] - 1s 3ms/step - loss: 16.2867 - mae: 16.2867 - val_loss: 15.9523 - val_mae: 15.9523\n",
            "Epoch 11/100\n",
            "310/310 [==============================] - 1s 3ms/step - loss: 16.2009 - mae: 16.2009 - val_loss: 15.9693 - val_mae: 15.9693\n",
            "Epoch 12/100\n",
            "310/310 [==============================] - 1s 3ms/step - loss: 16.2597 - mae: 16.2597 - val_loss: 16.0465 - val_mae: 16.0465\n",
            "Epoch 13/100\n",
            "310/310 [==============================] - 1s 2ms/step - loss: 16.2312 - mae: 16.2312 - val_loss: 16.0853 - val_mae: 16.0853\n",
            "97/97 [==============================] - 0s 1ms/step\n",
            "Epoch 1/100\n",
            "95/95 [==============================] - 1s 4ms/step - loss: 170.9066 - mae: 170.9066 - val_loss: 170.1245 - val_mae: 170.1245\n",
            "Epoch 2/100\n",
            "95/95 [==============================] - 0s 3ms/step - loss: 148.0036 - mae: 148.0036 - val_loss: 119.0831 - val_mae: 119.0831\n",
            "Epoch 3/100\n",
            "95/95 [==============================] - 0s 3ms/step - loss: 63.7045 - mae: 63.7045 - val_loss: 26.7611 - val_mae: 26.7611\n",
            "Epoch 4/100\n",
            "95/95 [==============================] - 0s 3ms/step - loss: 21.6233 - mae: 21.6233 - val_loss: 18.7887 - val_mae: 18.7887\n",
            "Epoch 5/100\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 15.7551 - mae: 15.7551 - val_loss: 14.5945 - val_mae: 14.5945\n",
            "Epoch 6/100\n",
            "95/95 [==============================] - 0s 3ms/step - loss: 13.3585 - mae: 13.3585 - val_loss: 13.2521 - val_mae: 13.2521\n",
            "Epoch 7/100\n",
            "95/95 [==============================] - 0s 3ms/step - loss: 12.7559 - mae: 12.7559 - val_loss: 13.0826 - val_mae: 13.0826\n",
            "Epoch 8/100\n",
            "95/95 [==============================] - 0s 3ms/step - loss: 12.7079 - mae: 12.7079 - val_loss: 13.0125 - val_mae: 13.0125\n",
            "Epoch 9/100\n",
            "95/95 [==============================] - 0s 3ms/step - loss: 12.6131 - mae: 12.6131 - val_loss: 12.9993 - val_mae: 12.9993\n",
            "Epoch 10/100\n",
            "95/95 [==============================] - 0s 3ms/step - loss: 12.7612 - mae: 12.7612 - val_loss: 13.0969 - val_mae: 13.0969\n",
            "Epoch 11/100\n",
            "95/95 [==============================] - 0s 3ms/step - loss: 12.6512 - mae: 12.6512 - val_loss: 13.4173 - val_mae: 13.4173\n",
            "Epoch 12/100\n",
            "95/95 [==============================] - 0s 3ms/step - loss: 12.6480 - mae: 12.6480 - val_loss: 13.0595 - val_mae: 13.0595\n",
            "Epoch 13/100\n",
            "95/95 [==============================] - 0s 3ms/step - loss: 12.6512 - mae: 12.6512 - val_loss: 13.0801 - val_mae: 13.0801\n",
            "Epoch 14/100\n",
            "95/95 [==============================] - 0s 3ms/step - loss: 12.6986 - mae: 12.6986 - val_loss: 13.0204 - val_mae: 13.0204\n",
            "Epoch 15/100\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 12.7307 - mae: 12.7307 - val_loss: 13.1601 - val_mae: 13.1601\n",
            "Epoch 16/100\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 12.6869 - mae: 12.6869 - val_loss: 13.0945 - val_mae: 13.0945\n",
            "Epoch 17/100\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 12.5836 - mae: 12.5836 - val_loss: 12.9904 - val_mae: 12.9904\n",
            "Epoch 18/100\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 12.6831 - mae: 12.6831 - val_loss: 13.2572 - val_mae: 13.2572\n",
            "Epoch 19/100\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 12.7175 - mae: 12.7175 - val_loss: 13.1891 - val_mae: 13.1891\n",
            "Epoch 20/100\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 12.7401 - mae: 12.7401 - val_loss: 13.1527 - val_mae: 13.1527\n",
            "Epoch 21/100\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 12.7279 - mae: 12.7279 - val_loss: 12.9291 - val_mae: 12.9291\n",
            "Epoch 22/100\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 12.6668 - mae: 12.6668 - val_loss: 13.1778 - val_mae: 13.1778\n",
            "Epoch 23/100\n",
            "95/95 [==============================] - 0s 3ms/step - loss: 12.6396 - mae: 12.6396 - val_loss: 13.1547 - val_mae: 13.1547\n",
            "Epoch 24/100\n",
            "95/95 [==============================] - 0s 3ms/step - loss: 12.6559 - mae: 12.6559 - val_loss: 12.9017 - val_mae: 12.9017\n",
            "Epoch 25/100\n",
            "95/95 [==============================] - 0s 3ms/step - loss: 12.6979 - mae: 12.6979 - val_loss: 13.1727 - val_mae: 13.1727\n",
            "Epoch 26/100\n",
            "95/95 [==============================] - 0s 3ms/step - loss: 12.7453 - mae: 12.7453 - val_loss: 13.2444 - val_mae: 13.2444\n",
            "Epoch 27/100\n",
            "95/95 [==============================] - 0s 3ms/step - loss: 12.6951 - mae: 12.6951 - val_loss: 12.9785 - val_mae: 12.9785\n",
            "Epoch 28/100\n",
            "95/95 [==============================] - 0s 3ms/step - loss: 12.7552 - mae: 12.7552 - val_loss: 13.1949 - val_mae: 13.1949\n",
            "Epoch 29/100\n",
            "95/95 [==============================] - 0s 3ms/step - loss: 12.6473 - mae: 12.6473 - val_loss: 13.1241 - val_mae: 13.1241\n",
            "Epoch 30/100\n",
            "95/95 [==============================] - 0s 3ms/step - loss: 12.7182 - mae: 12.7182 - val_loss: 12.9970 - val_mae: 12.9970\n",
            "Epoch 31/100\n",
            "95/95 [==============================] - 0s 3ms/step - loss: 12.6846 - mae: 12.6846 - val_loss: 12.9014 - val_mae: 12.9014\n",
            "Epoch 32/100\n",
            "95/95 [==============================] - 0s 3ms/step - loss: 12.5913 - mae: 12.5913 - val_loss: 12.9969 - val_mae: 12.9969\n",
            "Epoch 33/100\n",
            "95/95 [==============================] - 0s 3ms/step - loss: 12.7084 - mae: 12.7084 - val_loss: 13.9460 - val_mae: 13.9460\n",
            "Epoch 34/100\n",
            "95/95 [==============================] - 0s 3ms/step - loss: 12.7160 - mae: 12.7160 - val_loss: 13.2766 - val_mae: 13.2766\n",
            "Epoch 35/100\n",
            "95/95 [==============================] - 0s 3ms/step - loss: 12.7180 - mae: 12.7180 - val_loss: 13.1033 - val_mae: 13.1033\n",
            "Epoch 36/100\n",
            "95/95 [==============================] - 0s 2ms/step - loss: 12.5973 - mae: 12.5973 - val_loss: 13.0202 - val_mae: 13.0202\n",
            "Epoch 37/100\n",
            "95/95 [==============================] - 0s 3ms/step - loss: 12.6080 - mae: 12.6080 - val_loss: 12.9094 - val_mae: 12.9094\n",
            "Epoch 38/100\n",
            "95/95 [==============================] - 0s 3ms/step - loss: 12.6024 - mae: 12.6024 - val_loss: 13.0009 - val_mae: 13.0009\n",
            "Epoch 39/100\n",
            "95/95 [==============================] - 0s 3ms/step - loss: 12.5877 - mae: 12.5877 - val_loss: 13.2145 - val_mae: 13.2145\n",
            "Epoch 40/100\n",
            "95/95 [==============================] - 0s 3ms/step - loss: 12.6622 - mae: 12.6622 - val_loss: 13.1747 - val_mae: 13.1747\n",
            "Epoch 41/100\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 12.6252 - mae: 12.6252 - val_loss: 13.0800 - val_mae: 13.0800\n",
            "29/29 [==============================] - 0s 1ms/step\n",
            "Epoch 1/100\n",
            "310/310 [==============================] - 2s 3ms/step - loss: 73.1855 - mae: 73.1855 - val_loss: 21.2813 - val_mae: 21.2813\n",
            "Epoch 2/100\n",
            "310/310 [==============================] - 1s 3ms/step - loss: 13.1112 - mae: 13.1112 - val_loss: 11.8306 - val_mae: 11.8306\n",
            "Epoch 3/100\n",
            "310/310 [==============================] - 1s 3ms/step - loss: 11.7704 - mae: 11.7704 - val_loss: 11.7086 - val_mae: 11.7086\n",
            "Epoch 4/100\n",
            "310/310 [==============================] - 1s 3ms/step - loss: 11.7610 - mae: 11.7610 - val_loss: 11.7964 - val_mae: 11.7964\n",
            "Epoch 5/100\n",
            "310/310 [==============================] - 1s 2ms/step - loss: 11.6835 - mae: 11.6835 - val_loss: 11.6745 - val_mae: 11.6745\n",
            "Epoch 6/100\n",
            "310/310 [==============================] - 1s 3ms/step - loss: 11.7352 - mae: 11.7352 - val_loss: 11.8409 - val_mae: 11.8409\n",
            "Epoch 7/100\n",
            "310/310 [==============================] - 1s 3ms/step - loss: 11.7003 - mae: 11.7003 - val_loss: 11.8139 - val_mae: 11.8139\n",
            "Epoch 8/100\n",
            "310/310 [==============================] - 1s 3ms/step - loss: 11.6928 - mae: 11.6928 - val_loss: 11.8180 - val_mae: 11.8180\n",
            "Epoch 9/100\n",
            "310/310 [==============================] - 1s 3ms/step - loss: 11.7234 - mae: 11.7234 - val_loss: 11.9155 - val_mae: 11.9155\n",
            "Epoch 10/100\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 11.7530 - mae: 11.7530 - val_loss: 11.6651 - val_mae: 11.6651\n",
            "Epoch 11/100\n",
            "310/310 [==============================] - 1s 5ms/step - loss: 11.7345 - mae: 11.7345 - val_loss: 11.7957 - val_mae: 11.7957\n",
            "Epoch 12/100\n",
            "310/310 [==============================] - 1s 3ms/step - loss: 11.7270 - mae: 11.7270 - val_loss: 11.9992 - val_mae: 11.9992\n",
            "Epoch 13/100\n",
            "310/310 [==============================] - 1s 3ms/step - loss: 11.7467 - mae: 11.7467 - val_loss: 11.7645 - val_mae: 11.7645\n",
            "Epoch 14/100\n",
            "310/310 [==============================] - 1s 3ms/step - loss: 11.7223 - mae: 11.7223 - val_loss: 11.6582 - val_mae: 11.6582\n",
            "Epoch 15/100\n",
            "310/310 [==============================] - 1s 3ms/step - loss: 11.7332 - mae: 11.7332 - val_loss: 11.7726 - val_mae: 11.7726\n",
            "Epoch 16/100\n",
            "310/310 [==============================] - 1s 3ms/step - loss: 11.7157 - mae: 11.7157 - val_loss: 11.7231 - val_mae: 11.7231\n",
            "Epoch 17/100\n",
            "310/310 [==============================] - 1s 3ms/step - loss: 11.7093 - mae: 11.7093 - val_loss: 11.7070 - val_mae: 11.7070\n",
            "Epoch 18/100\n",
            "310/310 [==============================] - 1s 2ms/step - loss: 11.6808 - mae: 11.6808 - val_loss: 11.8024 - val_mae: 11.8024\n",
            "Epoch 19/100\n",
            "310/310 [==============================] - 1s 2ms/step - loss: 11.7042 - mae: 11.7042 - val_loss: 11.8908 - val_mae: 11.8908\n",
            "Epoch 20/100\n",
            "310/310 [==============================] - 1s 2ms/step - loss: 11.7228 - mae: 11.7228 - val_loss: 11.8126 - val_mae: 11.8126\n",
            "Epoch 21/100\n",
            "310/310 [==============================] - 1s 2ms/step - loss: 11.7323 - mae: 11.7323 - val_loss: 11.6643 - val_mae: 11.6643\n",
            "Epoch 22/100\n",
            "310/310 [==============================] - 1s 2ms/step - loss: 11.7149 - mae: 11.7149 - val_loss: 11.7301 - val_mae: 11.7301\n",
            "Epoch 23/100\n",
            "310/310 [==============================] - 1s 3ms/step - loss: 11.7247 - mae: 11.7247 - val_loss: 11.6608 - val_mae: 11.6608\n",
            "Epoch 24/100\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 11.7024 - mae: 11.7024 - val_loss: 11.6905 - val_mae: 11.6905\n",
            "98/98 [==============================] - 0s 2ms/step\n",
            "Epoch 1/100\n",
            "94/94 [==============================] - 2s 5ms/step - loss: 167.6472 - mae: 167.6472 - val_loss: 158.4022 - val_mae: 158.4022\n",
            "Epoch 2/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 134.7838 - mae: 134.7838 - val_loss: 96.8887 - val_mae: 96.8887\n",
            "Epoch 3/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 55.9892 - mae: 55.9892 - val_loss: 32.6508 - val_mae: 32.6508\n",
            "Epoch 4/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 25.6664 - mae: 25.6664 - val_loss: 20.2903 - val_mae: 20.2903\n",
            "Epoch 5/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 15.9132 - mae: 15.9132 - val_loss: 12.6976 - val_mae: 12.6976\n",
            "Epoch 6/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 10.7778 - mae: 10.7778 - val_loss: 10.9812 - val_mae: 10.9812\n",
            "Epoch 7/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 9.8903 - mae: 9.8903 - val_loss: 11.3899 - val_mae: 11.3899\n",
            "Epoch 8/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 9.9038 - mae: 9.9038 - val_loss: 10.8410 - val_mae: 10.8410\n",
            "Epoch 9/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 9.9839 - mae: 9.9839 - val_loss: 11.0658 - val_mae: 11.0658\n",
            "Epoch 10/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 9.9108 - mae: 9.9108 - val_loss: 11.1105 - val_mae: 11.1105\n",
            "Epoch 11/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 10.0566 - mae: 10.0566 - val_loss: 11.0185 - val_mae: 11.0185\n",
            "Epoch 12/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 9.9580 - mae: 9.9580 - val_loss: 11.2252 - val_mae: 11.2252\n",
            "Epoch 13/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 9.9460 - mae: 9.9460 - val_loss: 10.8485 - val_mae: 10.8485\n",
            "Epoch 14/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 9.9805 - mae: 9.9805 - val_loss: 11.1390 - val_mae: 11.1390\n",
            "Epoch 15/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 9.8235 - mae: 9.8235 - val_loss: 11.5920 - val_mae: 11.5920\n",
            "Epoch 16/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 9.9415 - mae: 9.9415 - val_loss: 10.8775 - val_mae: 10.8775\n",
            "Epoch 17/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 9.8174 - mae: 9.8174 - val_loss: 10.8290 - val_mae: 10.8290\n",
            "Epoch 18/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 9.8739 - mae: 9.8739 - val_loss: 10.9950 - val_mae: 10.9950\n",
            "Epoch 19/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 9.8447 - mae: 9.8447 - val_loss: 11.0407 - val_mae: 11.0407\n",
            "Epoch 20/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 9.9558 - mae: 9.9558 - val_loss: 11.1435 - val_mae: 11.1435\n",
            "Epoch 21/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 9.9312 - mae: 9.9312 - val_loss: 11.2928 - val_mae: 11.2928\n",
            "Epoch 22/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 9.8105 - mae: 9.8105 - val_loss: 10.8982 - val_mae: 10.8982\n",
            "Epoch 23/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 10.0276 - mae: 10.0276 - val_loss: 10.8712 - val_mae: 10.8712\n",
            "Epoch 24/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 9.9778 - mae: 9.9778 - val_loss: 10.9239 - val_mae: 10.9239\n",
            "Epoch 25/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 9.9947 - mae: 9.9947 - val_loss: 10.8817 - val_mae: 10.8817\n",
            "Epoch 26/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 9.9062 - mae: 9.9062 - val_loss: 11.1385 - val_mae: 11.1385\n",
            "Epoch 27/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 9.8833 - mae: 9.8833 - val_loss: 10.9481 - val_mae: 10.9481\n",
            "31/31 [==============================] - 0s 2ms/step\n",
            "Epoch 1/100\n",
            "311/311 [==============================] - 2s 4ms/step - loss: 89.8624 - mae: 89.8624 - val_loss: 16.4401 - val_mae: 16.4401\n",
            "Epoch 2/100\n",
            "311/311 [==============================] - 1s 3ms/step - loss: 15.0576 - mae: 15.0576 - val_loss: 14.7659 - val_mae: 14.7659\n",
            "Epoch 3/100\n",
            "311/311 [==============================] - 1s 2ms/step - loss: 14.9083 - mae: 14.9083 - val_loss: 14.8032 - val_mae: 14.8032\n",
            "Epoch 4/100\n",
            "311/311 [==============================] - 1s 3ms/step - loss: 14.9608 - mae: 14.9608 - val_loss: 14.6350 - val_mae: 14.6350\n",
            "Epoch 5/100\n",
            "311/311 [==============================] - 1s 2ms/step - loss: 14.8669 - mae: 14.8669 - val_loss: 14.8059 - val_mae: 14.8059\n",
            "Epoch 6/100\n",
            "311/311 [==============================] - 1s 3ms/step - loss: 14.9105 - mae: 14.9105 - val_loss: 14.6686 - val_mae: 14.6686\n",
            "Epoch 7/100\n",
            "311/311 [==============================] - 1s 3ms/step - loss: 14.8925 - mae: 14.8925 - val_loss: 14.7293 - val_mae: 14.7293\n",
            "Epoch 8/100\n",
            "311/311 [==============================] - 1s 2ms/step - loss: 14.9170 - mae: 14.9170 - val_loss: 14.6705 - val_mae: 14.6705\n",
            "Epoch 9/100\n",
            "311/311 [==============================] - 1s 3ms/step - loss: 14.8585 - mae: 14.8585 - val_loss: 14.7387 - val_mae: 14.7387\n",
            "Epoch 10/100\n",
            "311/311 [==============================] - 1s 3ms/step - loss: 14.8995 - mae: 14.8995 - val_loss: 14.7421 - val_mae: 14.7421\n",
            "Epoch 11/100\n",
            "311/311 [==============================] - 1s 3ms/step - loss: 14.9522 - mae: 14.9522 - val_loss: 14.6719 - val_mae: 14.6719\n",
            "Epoch 12/100\n",
            "311/311 [==============================] - 1s 3ms/step - loss: 14.8912 - mae: 14.8912 - val_loss: 14.6038 - val_mae: 14.6038\n",
            "Epoch 13/100\n",
            "311/311 [==============================] - 1s 3ms/step - loss: 14.8704 - mae: 14.8704 - val_loss: 14.7552 - val_mae: 14.7552\n",
            "Epoch 14/100\n",
            "311/311 [==============================] - 1s 3ms/step - loss: 14.8569 - mae: 14.8569 - val_loss: 14.8054 - val_mae: 14.8054\n",
            "Epoch 15/100\n",
            "311/311 [==============================] - 1s 4ms/step - loss: 14.8796 - mae: 14.8796 - val_loss: 14.6293 - val_mae: 14.6293\n",
            "Epoch 16/100\n",
            "311/311 [==============================] - 1s 3ms/step - loss: 14.8918 - mae: 14.8918 - val_loss: 14.7883 - val_mae: 14.7883\n",
            "Epoch 17/100\n",
            "311/311 [==============================] - 1s 3ms/step - loss: 14.8729 - mae: 14.8729 - val_loss: 14.6913 - val_mae: 14.6913\n",
            "Epoch 18/100\n",
            "311/311 [==============================] - 1s 3ms/step - loss: 14.8530 - mae: 14.8530 - val_loss: 14.8387 - val_mae: 14.8387\n",
            "Epoch 19/100\n",
            "311/311 [==============================] - 1s 2ms/step - loss: 14.9453 - mae: 14.9453 - val_loss: 14.7339 - val_mae: 14.7339\n",
            "Epoch 20/100\n",
            "311/311 [==============================] - 1s 3ms/step - loss: 14.8944 - mae: 14.8944 - val_loss: 15.0446 - val_mae: 15.0446\n",
            "Epoch 21/100\n",
            "311/311 [==============================] - 1s 2ms/step - loss: 14.9081 - mae: 14.9081 - val_loss: 14.9320 - val_mae: 14.9320\n",
            "Epoch 22/100\n",
            "311/311 [==============================] - 1s 3ms/step - loss: 14.8706 - mae: 14.8706 - val_loss: 14.5807 - val_mae: 14.5807\n",
            "Epoch 23/100\n",
            "311/311 [==============================] - 1s 2ms/step - loss: 14.9010 - mae: 14.9010 - val_loss: 14.5634 - val_mae: 14.5634\n",
            "Epoch 24/100\n",
            "311/311 [==============================] - 1s 3ms/step - loss: 14.8913 - mae: 14.8913 - val_loss: 14.6904 - val_mae: 14.6904\n",
            "Epoch 25/100\n",
            "311/311 [==============================] - 1s 3ms/step - loss: 14.8881 - mae: 14.8881 - val_loss: 14.6595 - val_mae: 14.6595\n",
            "Epoch 26/100\n",
            "311/311 [==============================] - 1s 3ms/step - loss: 14.8925 - mae: 14.8925 - val_loss: 14.7131 - val_mae: 14.7131\n",
            "Epoch 27/100\n",
            "311/311 [==============================] - 1s 3ms/step - loss: 14.8993 - mae: 14.8993 - val_loss: 14.6183 - val_mae: 14.6183\n",
            "Epoch 28/100\n",
            "311/311 [==============================] - 1s 4ms/step - loss: 14.8787 - mae: 14.8787 - val_loss: 14.6467 - val_mae: 14.6467\n",
            "Epoch 29/100\n",
            "311/311 [==============================] - 1s 4ms/step - loss: 14.8494 - mae: 14.8494 - val_loss: 14.6586 - val_mae: 14.6586\n",
            "Epoch 30/100\n",
            "311/311 [==============================] - 1s 3ms/step - loss: 14.8409 - mae: 14.8409 - val_loss: 14.9019 - val_mae: 14.9019\n",
            "Epoch 31/100\n",
            "311/311 [==============================] - 1s 3ms/step - loss: 14.9274 - mae: 14.9274 - val_loss: 14.6379 - val_mae: 14.6379\n",
            "Epoch 32/100\n",
            "311/311 [==============================] - 1s 3ms/step - loss: 14.8475 - mae: 14.8475 - val_loss: 14.6726 - val_mae: 14.6726\n",
            "Epoch 33/100\n",
            "311/311 [==============================] - 1s 2ms/step - loss: 14.9109 - mae: 14.9109 - val_loss: 14.7348 - val_mae: 14.7348\n",
            "97/97 [==============================] - 0s 1ms/step\n",
            "Epoch 1/100\n",
            "94/94 [==============================] - 2s 13ms/step - loss: 224.5697 - mae: 224.5697 - val_loss: 215.3272 - val_mae: 215.3272\n",
            "Epoch 2/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 206.3160 - mae: 206.3160 - val_loss: 171.8789 - val_mae: 171.8789\n",
            "Epoch 3/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 111.1103 - mae: 111.1103 - val_loss: 41.8694 - val_mae: 41.8694\n",
            "Epoch 4/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 28.7054 - mae: 28.7054 - val_loss: 21.0309 - val_mae: 21.0309\n",
            "Epoch 5/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 17.8605 - mae: 17.8605 - val_loss: 16.4717 - val_mae: 16.4717\n",
            "Epoch 6/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 16.0353 - mae: 16.0353 - val_loss: 16.2048 - val_mae: 16.2048\n",
            "Epoch 7/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 16.2046 - mae: 16.2046 - val_loss: 16.4829 - val_mae: 16.4829\n",
            "Epoch 8/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 16.1615 - mae: 16.1615 - val_loss: 16.0410 - val_mae: 16.0410\n",
            "Epoch 9/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 16.1618 - mae: 16.1618 - val_loss: 16.0826 - val_mae: 16.0826\n",
            "Epoch 10/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 16.1301 - mae: 16.1301 - val_loss: 16.0777 - val_mae: 16.0777\n",
            "Epoch 11/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 16.0832 - mae: 16.0832 - val_loss: 16.4977 - val_mae: 16.4977\n",
            "Epoch 12/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 16.1613 - mae: 16.1613 - val_loss: 16.1120 - val_mae: 16.1120\n",
            "Epoch 13/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 16.0603 - mae: 16.0603 - val_loss: 15.9146 - val_mae: 15.9146\n",
            "Epoch 14/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 16.1805 - mae: 16.1805 - val_loss: 15.9627 - val_mae: 15.9627\n",
            "Epoch 15/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 16.0161 - mae: 16.0161 - val_loss: 16.2011 - val_mae: 16.2011\n",
            "Epoch 16/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 16.1429 - mae: 16.1429 - val_loss: 16.0751 - val_mae: 16.0751\n",
            "Epoch 17/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 16.1351 - mae: 16.1351 - val_loss: 15.8266 - val_mae: 15.8266\n",
            "Epoch 18/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 16.0796 - mae: 16.0796 - val_loss: 15.9307 - val_mae: 15.9307\n",
            "Epoch 19/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 16.1272 - mae: 16.1272 - val_loss: 16.2227 - val_mae: 16.2227\n",
            "Epoch 20/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 16.1513 - mae: 16.1513 - val_loss: 16.0369 - val_mae: 16.0369\n",
            "Epoch 21/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 16.0450 - mae: 16.0450 - val_loss: 16.0198 - val_mae: 16.0198\n",
            "Epoch 22/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 16.0767 - mae: 16.0767 - val_loss: 16.0142 - val_mae: 16.0142\n",
            "Epoch 23/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 15.9862 - mae: 15.9862 - val_loss: 16.1100 - val_mae: 16.1100\n",
            "Epoch 24/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 16.1074 - mae: 16.1074 - val_loss: 16.1313 - val_mae: 16.1313\n",
            "Epoch 25/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 16.1838 - mae: 16.1838 - val_loss: 15.9456 - val_mae: 15.9456\n",
            "Epoch 26/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 16.1690 - mae: 16.1690 - val_loss: 16.1033 - val_mae: 16.1033\n",
            "Epoch 27/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 16.0701 - mae: 16.0701 - val_loss: 16.0467 - val_mae: 16.0467\n",
            "31/31 [==============================] - 0s 2ms/step\n",
            "Epoch 1/100\n",
            "309/309 [==============================] - 2s 4ms/step - loss: 87.9508 - mae: 87.9508 - val_loss: 24.9328 - val_mae: 24.9328\n",
            "Epoch 2/100\n",
            "309/309 [==============================] - 1s 3ms/step - loss: 20.4993 - mae: 20.4993 - val_loss: 19.8212 - val_mae: 19.8212\n",
            "Epoch 3/100\n",
            "309/309 [==============================] - 1s 3ms/step - loss: 19.8892 - mae: 19.8892 - val_loss: 19.9873 - val_mae: 19.9873\n",
            "Epoch 4/100\n",
            "309/309 [==============================] - 1s 3ms/step - loss: 19.8640 - mae: 19.8640 - val_loss: 19.9106 - val_mae: 19.9106\n",
            "Epoch 5/100\n",
            "309/309 [==============================] - 1s 3ms/step - loss: 19.8332 - mae: 19.8332 - val_loss: 20.0062 - val_mae: 20.0062\n",
            "Epoch 6/100\n",
            "309/309 [==============================] - 1s 3ms/step - loss: 19.8818 - mae: 19.8818 - val_loss: 19.9033 - val_mae: 19.9033\n",
            "Epoch 7/100\n",
            "309/309 [==============================] - 1s 3ms/step - loss: 19.8335 - mae: 19.8335 - val_loss: 20.0527 - val_mae: 20.0527\n",
            "Epoch 8/100\n",
            "309/309 [==============================] - 1s 3ms/step - loss: 19.8454 - mae: 19.8454 - val_loss: 19.8637 - val_mae: 19.8637\n",
            "Epoch 9/100\n",
            "309/309 [==============================] - 1s 3ms/step - loss: 19.8579 - mae: 19.8579 - val_loss: 19.8333 - val_mae: 19.8333\n",
            "Epoch 10/100\n",
            "309/309 [==============================] - 1s 4ms/step - loss: 19.9218 - mae: 19.9218 - val_loss: 20.2152 - val_mae: 20.2152\n",
            "Epoch 11/100\n",
            "309/309 [==============================] - 1s 4ms/step - loss: 19.8636 - mae: 19.8636 - val_loss: 20.1421 - val_mae: 20.1421\n",
            "Epoch 12/100\n",
            "309/309 [==============================] - 1s 4ms/step - loss: 19.9110 - mae: 19.9110 - val_loss: 19.9276 - val_mae: 19.9276\n",
            "98/98 [==============================] - 0s 1ms/step\n",
            "Epoch 1/100\n",
            "96/96 [==============================] - 1s 5ms/step - loss: 230.5826 - mae: 230.5826 - val_loss: 215.4868 - val_mae: 215.4868\n",
            "Epoch 2/100\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 209.4678 - mae: 209.4678 - val_loss: 172.0311 - val_mae: 172.0311\n",
            "Epoch 3/100\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 110.1365 - mae: 110.1365 - val_loss: 34.4268 - val_mae: 34.4268\n",
            "Epoch 4/100\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 20.8484 - mae: 20.8484 - val_loss: 15.1349 - val_mae: 15.1349\n",
            "Epoch 5/100\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 15.1753 - mae: 15.1753 - val_loss: 15.1881 - val_mae: 15.1881\n",
            "Epoch 6/100\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 15.0445 - mae: 15.0445 - val_loss: 14.2129 - val_mae: 14.2129\n",
            "Epoch 7/100\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 15.1305 - mae: 15.1305 - val_loss: 14.5597 - val_mae: 14.5597\n",
            "Epoch 8/100\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 15.0016 - mae: 15.0016 - val_loss: 14.6767 - val_mae: 14.6767\n",
            "Epoch 9/100\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 15.0920 - mae: 15.0920 - val_loss: 14.3656 - val_mae: 14.3656\n",
            "Epoch 10/100\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 14.8880 - mae: 14.8880 - val_loss: 14.4819 - val_mae: 14.4819\n",
            "Epoch 11/100\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 15.0650 - mae: 15.0650 - val_loss: 14.4309 - val_mae: 14.4309\n",
            "Epoch 12/100\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 15.0413 - mae: 15.0413 - val_loss: 14.6705 - val_mae: 14.6705\n",
            "Epoch 13/100\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 14.9976 - mae: 14.9976 - val_loss: 14.3460 - val_mae: 14.3460\n",
            "Epoch 14/100\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 14.9083 - mae: 14.9083 - val_loss: 14.4572 - val_mae: 14.4572\n",
            "Epoch 15/100\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 14.9514 - mae: 14.9514 - val_loss: 14.6541 - val_mae: 14.6541\n",
            "Epoch 16/100\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 14.9521 - mae: 14.9521 - val_loss: 14.6243 - val_mae: 14.6243\n",
            "28/28 [==============================] - 0s 1ms/step\n",
            "Epoch 1/100\n",
            "308/308 [==============================] - 2s 4ms/step - loss: 119.0319 - mae: 119.0319 - val_loss: 11.6933 - val_mae: 11.6933\n",
            "Epoch 2/100\n",
            "308/308 [==============================] - 1s 3ms/step - loss: 9.4222 - mae: 9.4222 - val_loss: 9.6522 - val_mae: 9.6522\n",
            "Epoch 3/100\n",
            "308/308 [==============================] - 1s 3ms/step - loss: 9.3278 - mae: 9.3278 - val_loss: 9.3368 - val_mae: 9.3368\n",
            "Epoch 4/100\n",
            "308/308 [==============================] - 1s 4ms/step - loss: 9.3353 - mae: 9.3353 - val_loss: 9.3361 - val_mae: 9.3361\n",
            "Epoch 5/100\n",
            "308/308 [==============================] - 1s 4ms/step - loss: 9.3126 - mae: 9.3126 - val_loss: 9.4360 - val_mae: 9.4360\n",
            "Epoch 6/100\n",
            "308/308 [==============================] - 1s 3ms/step - loss: 9.3186 - mae: 9.3186 - val_loss: 9.4143 - val_mae: 9.4143\n",
            "Epoch 7/100\n",
            "308/308 [==============================] - 1s 3ms/step - loss: 9.3345 - mae: 9.3345 - val_loss: 9.3058 - val_mae: 9.3058\n",
            "Epoch 8/100\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 9.3239 - mae: 9.3239 - val_loss: 9.3196 - val_mae: 9.3196\n",
            "Epoch 9/100\n",
            "308/308 [==============================] - 1s 3ms/step - loss: 9.3350 - mae: 9.3350 - val_loss: 9.3777 - val_mae: 9.3777\n",
            "Epoch 10/100\n",
            "308/308 [==============================] - 1s 3ms/step - loss: 9.3744 - mae: 9.3744 - val_loss: 9.3290 - val_mae: 9.3290\n",
            "Epoch 11/100\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 9.3682 - mae: 9.3682 - val_loss: 9.3267 - val_mae: 9.3267\n",
            "Epoch 12/100\n",
            "308/308 [==============================] - 1s 3ms/step - loss: 9.3563 - mae: 9.3563 - val_loss: 9.4056 - val_mae: 9.4056\n",
            "Epoch 13/100\n",
            "308/308 [==============================] - 1s 3ms/step - loss: 9.3196 - mae: 9.3196 - val_loss: 9.4410 - val_mae: 9.4410\n",
            "Epoch 14/100\n",
            "308/308 [==============================] - 1s 3ms/step - loss: 9.3136 - mae: 9.3136 - val_loss: 9.3480 - val_mae: 9.3480\n",
            "Epoch 15/100\n",
            "308/308 [==============================] - 1s 3ms/step - loss: 9.3011 - mae: 9.3011 - val_loss: 9.3883 - val_mae: 9.3883\n",
            "Epoch 16/100\n",
            "308/308 [==============================] - 1s 3ms/step - loss: 9.4017 - mae: 9.4017 - val_loss: 9.3054 - val_mae: 9.3054\n",
            "Epoch 17/100\n",
            "308/308 [==============================] - 1s 3ms/step - loss: 9.3535 - mae: 9.3535 - val_loss: 9.3158 - val_mae: 9.3158\n",
            "Epoch 18/100\n",
            "308/308 [==============================] - 1s 4ms/step - loss: 9.2869 - mae: 9.2869 - val_loss: 9.4721 - val_mae: 9.4721\n",
            "Epoch 19/100\n",
            "308/308 [==============================] - 1s 4ms/step - loss: 9.3086 - mae: 9.3086 - val_loss: 9.5322 - val_mae: 9.5322\n",
            "Epoch 20/100\n",
            "308/308 [==============================] - 1s 3ms/step - loss: 9.3442 - mae: 9.3442 - val_loss: 9.4213 - val_mae: 9.4213\n",
            "Epoch 21/100\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 9.2913 - mae: 9.2913 - val_loss: 9.3423 - val_mae: 9.3423\n",
            "Epoch 22/100\n",
            "308/308 [==============================] - 1s 3ms/step - loss: 9.3433 - mae: 9.3433 - val_loss: 9.3007 - val_mae: 9.3007\n",
            "Epoch 23/100\n",
            "308/308 [==============================] - 1s 3ms/step - loss: 9.3662 - mae: 9.3662 - val_loss: 9.5762 - val_mae: 9.5762\n",
            "Epoch 24/100\n",
            "308/308 [==============================] - 1s 3ms/step - loss: 9.3204 - mae: 9.3204 - val_loss: 9.4212 - val_mae: 9.4212\n",
            "Epoch 25/100\n",
            "308/308 [==============================] - 1s 3ms/step - loss: 9.3071 - mae: 9.3071 - val_loss: 9.4400 - val_mae: 9.4400\n",
            "Epoch 26/100\n",
            "308/308 [==============================] - 1s 3ms/step - loss: 9.2976 - mae: 9.2976 - val_loss: 9.6500 - val_mae: 9.6500\n",
            "Epoch 27/100\n",
            "308/308 [==============================] - 1s 3ms/step - loss: 9.3072 - mae: 9.3072 - val_loss: 9.3125 - val_mae: 9.3125\n",
            "Epoch 28/100\n",
            "308/308 [==============================] - 1s 3ms/step - loss: 9.3262 - mae: 9.3262 - val_loss: 9.7398 - val_mae: 9.7398\n",
            "Epoch 29/100\n",
            "308/308 [==============================] - 1s 3ms/step - loss: 9.3142 - mae: 9.3142 - val_loss: 9.3859 - val_mae: 9.3859\n",
            "Epoch 30/100\n",
            "308/308 [==============================] - 1s 3ms/step - loss: 9.2893 - mae: 9.2893 - val_loss: 9.3696 - val_mae: 9.3696\n",
            "Epoch 31/100\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 9.3274 - mae: 9.3274 - val_loss: 9.5797 - val_mae: 9.5797\n",
            "Epoch 32/100\n",
            "308/308 [==============================] - 1s 4ms/step - loss: 9.3646 - mae: 9.3646 - val_loss: 9.4384 - val_mae: 9.4384\n",
            "100/100 [==============================] - 0s 2ms/step\n",
            "Epoch 1/100\n",
            "93/93 [==============================] - 2s 8ms/step - loss: 253.6957 - mae: 253.6957 - val_loss: 255.7767 - val_mae: 255.7767\n",
            "Epoch 2/100\n",
            "93/93 [==============================] - 0s 4ms/step - loss: 235.3088 - mae: 235.3088 - val_loss: 213.0756 - val_mae: 213.0756\n",
            "Epoch 3/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 143.6164 - mae: 143.6164 - val_loss: 64.5962 - val_mae: 64.5962\n",
            "Epoch 4/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 24.3128 - mae: 24.3128 - val_loss: 7.9416 - val_mae: 7.9416\n",
            "Epoch 5/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 8.3468 - mae: 8.3468 - val_loss: 7.9751 - val_mae: 7.9751\n",
            "Epoch 6/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 8.3734 - mae: 8.3734 - val_loss: 7.4699 - val_mae: 7.4699\n",
            "Epoch 7/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 8.2355 - mae: 8.2355 - val_loss: 7.8466 - val_mae: 7.8466\n",
            "Epoch 8/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 8.2586 - mae: 8.2586 - val_loss: 8.0921 - val_mae: 8.0921\n",
            "Epoch 9/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 8.3027 - mae: 8.3027 - val_loss: 7.5449 - val_mae: 7.5449\n",
            "Epoch 10/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 8.2820 - mae: 8.2820 - val_loss: 7.5515 - val_mae: 7.5515\n",
            "Epoch 11/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 8.3172 - mae: 8.3172 - val_loss: 8.0164 - val_mae: 8.0164\n",
            "Epoch 12/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 8.2660 - mae: 8.2660 - val_loss: 7.8767 - val_mae: 7.8767\n",
            "Epoch 13/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 8.3311 - mae: 8.3311 - val_loss: 7.4217 - val_mae: 7.4217\n",
            "Epoch 14/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 8.2343 - mae: 8.2343 - val_loss: 7.5279 - val_mae: 7.5279\n",
            "Epoch 15/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 8.2639 - mae: 8.2639 - val_loss: 8.0629 - val_mae: 8.0629\n",
            "Epoch 16/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 8.3179 - mae: 8.3179 - val_loss: 8.0023 - val_mae: 8.0023\n",
            "Epoch 17/100\n",
            "93/93 [==============================] - 0s 4ms/step - loss: 8.3569 - mae: 8.3569 - val_loss: 8.0934 - val_mae: 8.0934\n",
            "Epoch 18/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 8.3212 - mae: 8.3212 - val_loss: 7.6007 - val_mae: 7.6007\n",
            "Epoch 19/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 8.2673 - mae: 8.2673 - val_loss: 8.0731 - val_mae: 8.0731\n",
            "Epoch 20/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 8.3831 - mae: 8.3831 - val_loss: 8.0215 - val_mae: 8.0215\n",
            "Epoch 21/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 8.3783 - mae: 8.3783 - val_loss: 7.5519 - val_mae: 7.5519\n",
            "Epoch 22/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 8.3602 - mae: 8.3602 - val_loss: 7.6993 - val_mae: 7.6993\n",
            "Epoch 23/100\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 8.1902 - mae: 8.1902 - val_loss: 7.9486 - val_mae: 7.9486\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "Epoch 1/100\n",
            "310/310 [==============================] - 3s 5ms/step - loss: 113.7539 - mae: 113.7539 - val_loss: 17.6472 - val_mae: 17.6472\n",
            "Epoch 2/100\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 13.3684 - mae: 13.3684 - val_loss: 13.4264 - val_mae: 13.4264\n",
            "Epoch 3/100\n",
            "310/310 [==============================] - 1s 3ms/step - loss: 13.0499 - mae: 13.0499 - val_loss: 13.3699 - val_mae: 13.3699\n",
            "Epoch 4/100\n",
            "310/310 [==============================] - 1s 3ms/step - loss: 13.0710 - mae: 13.0710 - val_loss: 13.1746 - val_mae: 13.1746\n",
            "Epoch 5/100\n",
            "310/310 [==============================] - 1s 3ms/step - loss: 13.0606 - mae: 13.0606 - val_loss: 13.0676 - val_mae: 13.0676\n",
            "Epoch 6/100\n",
            "310/310 [==============================] - 1s 3ms/step - loss: 13.0656 - mae: 13.0656 - val_loss: 13.0805 - val_mae: 13.0805\n",
            "Epoch 7/100\n",
            "310/310 [==============================] - 1s 3ms/step - loss: 13.0397 - mae: 13.0397 - val_loss: 13.0527 - val_mae: 13.0527\n",
            "Epoch 8/100\n",
            "310/310 [==============================] - 1s 3ms/step - loss: 13.0841 - mae: 13.0841 - val_loss: 13.0634 - val_mae: 13.0634\n",
            "Epoch 9/100\n",
            "310/310 [==============================] - 1s 3ms/step - loss: 13.0158 - mae: 13.0158 - val_loss: 13.3953 - val_mae: 13.3953\n",
            "Epoch 10/100\n",
            "310/310 [==============================] - 1s 3ms/step - loss: 13.0137 - mae: 13.0137 - val_loss: 13.0320 - val_mae: 13.0320\n",
            "Epoch 11/100\n",
            "310/310 [==============================] - 1s 3ms/step - loss: 13.0932 - mae: 13.0932 - val_loss: 12.9573 - val_mae: 12.9573\n",
            "Epoch 12/100\n",
            "310/310 [==============================] - 1s 3ms/step - loss: 13.0156 - mae: 13.0156 - val_loss: 13.0543 - val_mae: 13.0543\n",
            "Epoch 13/100\n",
            "310/310 [==============================] - 1s 3ms/step - loss: 12.9951 - mae: 12.9951 - val_loss: 13.2899 - val_mae: 13.2899\n",
            "Epoch 14/100\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 13.0059 - mae: 13.0059 - val_loss: 12.9346 - val_mae: 12.9346\n",
            "Epoch 15/100\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 12.9991 - mae: 12.9991 - val_loss: 12.9960 - val_mae: 12.9960\n",
            "Epoch 16/100\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 13.0351 - mae: 13.0351 - val_loss: 13.2147 - val_mae: 13.2147\n",
            "Epoch 17/100\n",
            "310/310 [==============================] - 1s 2ms/step - loss: 13.0766 - mae: 13.0766 - val_loss: 13.1970 - val_mae: 13.1970\n",
            "Epoch 18/100\n",
            "310/310 [==============================] - 1s 3ms/step - loss: 13.0868 - mae: 13.0868 - val_loss: 12.9937 - val_mae: 12.9937\n",
            "Epoch 19/100\n",
            "310/310 [==============================] - 1s 3ms/step - loss: 13.0511 - mae: 13.0511 - val_loss: 13.6204 - val_mae: 13.6204\n",
            "Epoch 20/100\n",
            "310/310 [==============================] - 1s 3ms/step - loss: 13.0368 - mae: 13.0368 - val_loss: 12.9957 - val_mae: 12.9957\n",
            "Epoch 21/100\n",
            "310/310 [==============================] - 1s 3ms/step - loss: 13.0012 - mae: 13.0012 - val_loss: 13.1051 - val_mae: 13.1051\n",
            "Epoch 22/100\n",
            "310/310 [==============================] - 1s 3ms/step - loss: 13.0623 - mae: 13.0623 - val_loss: 13.0427 - val_mae: 13.0427\n",
            "Epoch 23/100\n",
            "310/310 [==============================] - 1s 3ms/step - loss: 13.0889 - mae: 13.0889 - val_loss: 13.0917 - val_mae: 13.0917\n",
            "Epoch 24/100\n",
            "310/310 [==============================] - 1s 3ms/step - loss: 13.0748 - mae: 13.0748 - val_loss: 12.9163 - val_mae: 12.9163\n",
            "Epoch 25/100\n",
            "310/310 [==============================] - 1s 3ms/step - loss: 13.0604 - mae: 13.0604 - val_loss: 13.1482 - val_mae: 13.1482\n",
            "Epoch 26/100\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 12.9842 - mae: 12.9842 - val_loss: 13.2334 - val_mae: 13.2334\n",
            "Epoch 27/100\n",
            "310/310 [==============================] - 1s 3ms/step - loss: 13.0425 - mae: 13.0425 - val_loss: 13.3131 - val_mae: 13.3131\n",
            "Epoch 28/100\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 13.0605 - mae: 13.0605 - val_loss: 13.0316 - val_mae: 13.0316\n",
            "Epoch 29/100\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 13.0378 - mae: 13.0378 - val_loss: 13.1064 - val_mae: 13.1064\n",
            "Epoch 30/100\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 13.0317 - mae: 13.0317 - val_loss: 13.0540 - val_mae: 13.0540\n",
            "Epoch 31/100\n",
            "310/310 [==============================] - 1s 3ms/step - loss: 13.0167 - mae: 13.0167 - val_loss: 13.3266 - val_mae: 13.3266\n",
            "Epoch 32/100\n",
            "310/310 [==============================] - 1s 3ms/step - loss: 13.0823 - mae: 13.0823 - val_loss: 13.0795 - val_mae: 13.0795\n",
            "Epoch 33/100\n",
            "310/310 [==============================] - 1s 3ms/step - loss: 13.0412 - mae: 13.0412 - val_loss: 13.1741 - val_mae: 13.1741\n",
            "Epoch 34/100\n",
            "310/310 [==============================] - 1s 3ms/step - loss: 13.0263 - mae: 13.0263 - val_loss: 12.9360 - val_mae: 12.9360\n",
            "97/97 [==============================] - 0s 2ms/step\n",
            "Epoch 1/100\n",
            "96/96 [==============================] - 1s 5ms/step - loss: 245.6661 - mae: 245.6661 - val_loss: 255.3890 - val_mae: 255.3890\n",
            "Epoch 2/100\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 223.2744 - mae: 223.2744 - val_loss: 202.6988 - val_mae: 202.6988\n",
            "Epoch 3/100\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 121.3727 - mae: 121.3727 - val_loss: 45.6375 - val_mae: 45.6375\n",
            "Epoch 4/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 20.0339 - mae: 20.0339 - val_loss: 10.7272 - val_mae: 10.7272\n",
            "Epoch 5/100\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 11.1124 - mae: 11.1124 - val_loss: 11.2945 - val_mae: 11.2945\n",
            "Epoch 6/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 11.2333 - mae: 11.2333 - val_loss: 10.8856 - val_mae: 10.8856\n",
            "Epoch 7/100\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 11.0811 - mae: 11.0811 - val_loss: 10.7922 - val_mae: 10.7922\n",
            "Epoch 8/100\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 11.0200 - mae: 11.0200 - val_loss: 10.8091 - val_mae: 10.8091\n",
            "Epoch 9/100\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 11.1039 - mae: 11.1039 - val_loss: 10.9047 - val_mae: 10.9047\n",
            "Epoch 10/100\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 11.1656 - mae: 11.1656 - val_loss: 10.7781 - val_mae: 10.7781\n",
            "Epoch 11/100\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 11.1429 - mae: 11.1429 - val_loss: 10.7331 - val_mae: 10.7331\n",
            "Epoch 12/100\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 11.0142 - mae: 11.0142 - val_loss: 10.7424 - val_mae: 10.7424\n",
            "Epoch 13/100\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 11.1950 - mae: 11.1950 - val_loss: 10.6730 - val_mae: 10.6730\n",
            "Epoch 14/100\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 11.1628 - mae: 11.1628 - val_loss: 11.0422 - val_mae: 11.0422\n",
            "Epoch 15/100\n",
            "96/96 [==============================] - 0s 5ms/step - loss: 11.0145 - mae: 11.0145 - val_loss: 11.0416 - val_mae: 11.0416\n",
            "Epoch 16/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 11.1997 - mae: 11.1997 - val_loss: 10.7171 - val_mae: 10.7171\n",
            "Epoch 17/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 11.0544 - mae: 11.0544 - val_loss: 10.8427 - val_mae: 10.8427\n",
            "Epoch 18/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 11.1709 - mae: 11.1709 - val_loss: 10.8361 - val_mae: 10.8361\n",
            "Epoch 19/100\n",
            "96/96 [==============================] - 0s 5ms/step - loss: 11.1209 - mae: 11.1209 - val_loss: 10.9552 - val_mae: 10.9552\n",
            "Epoch 20/100\n",
            "96/96 [==============================] - 0s 5ms/step - loss: 11.1779 - mae: 11.1779 - val_loss: 10.8503 - val_mae: 10.8503\n",
            "Epoch 21/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 11.0671 - mae: 11.0671 - val_loss: 10.5646 - val_mae: 10.5646\n",
            "Epoch 22/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 11.0085 - mae: 11.0085 - val_loss: 10.8664 - val_mae: 10.8664\n",
            "Epoch 23/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 11.1049 - mae: 11.1049 - val_loss: 10.8509 - val_mae: 10.8509\n",
            "Epoch 24/100\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 11.0776 - mae: 11.0776 - val_loss: 11.2344 - val_mae: 11.2344\n",
            "Epoch 25/100\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 11.0901 - mae: 11.0901 - val_loss: 10.7031 - val_mae: 10.7031\n",
            "Epoch 26/100\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 11.0640 - mae: 11.0640 - val_loss: 10.6484 - val_mae: 10.6484\n",
            "Epoch 27/100\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 11.0977 - mae: 11.0977 - val_loss: 11.0514 - val_mae: 11.0514\n",
            "Epoch 28/100\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 10.9540 - mae: 10.9540 - val_loss: 10.5771 - val_mae: 10.5771\n",
            "Epoch 29/100\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 11.0552 - mae: 11.0552 - val_loss: 11.0561 - val_mae: 11.0561\n",
            "Epoch 30/100\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 11.1432 - mae: 11.1432 - val_loss: 10.8021 - val_mae: 10.8021\n",
            "Epoch 31/100\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 11.0393 - mae: 11.0393 - val_loss: 10.5228 - val_mae: 10.5228\n",
            "Epoch 32/100\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 10.9494 - mae: 10.9494 - val_loss: 11.0082 - val_mae: 11.0082\n",
            "Epoch 33/100\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 11.0569 - mae: 11.0569 - val_loss: 10.8907 - val_mae: 10.8907\n",
            "Epoch 34/100\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 11.0557 - mae: 11.0557 - val_loss: 10.5902 - val_mae: 10.5902\n",
            "Epoch 35/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 10.9554 - mae: 10.9554 - val_loss: 10.7267 - val_mae: 10.7267\n",
            "Epoch 36/100\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 11.0372 - mae: 11.0372 - val_loss: 10.8241 - val_mae: 10.8241\n",
            "Epoch 37/100\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 11.0239 - mae: 11.0239 - val_loss: 10.7024 - val_mae: 10.7024\n",
            "Epoch 38/100\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 11.0443 - mae: 11.0443 - val_loss: 10.7340 - val_mae: 10.7340\n",
            "Epoch 39/100\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 11.0685 - mae: 11.0685 - val_loss: 10.6821 - val_mae: 10.6821\n",
            "Epoch 40/100\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 11.1713 - mae: 11.1713 - val_loss: 11.5190 - val_mae: 11.5190\n",
            "Epoch 41/100\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 11.0751 - mae: 11.0751 - val_loss: 10.8115 - val_mae: 10.8115\n",
            "28/28 [==============================] - 0s 1ms/step\n",
            "Epoch 1/100\n",
            "312/312 [==============================] - 2s 3ms/step - loss: 108.2070 - mae: 108.2070 - val_loss: 15.2361 - val_mae: 15.2361\n",
            "Epoch 2/100\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 6.2657 - mae: 6.2657 - val_loss: 5.3853 - val_mae: 5.3853\n",
            "Epoch 3/100\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 5.6217 - mae: 5.6217 - val_loss: 5.6037 - val_mae: 5.6037\n",
            "Epoch 4/100\n",
            "312/312 [==============================] - 1s 4ms/step - loss: 5.6427 - mae: 5.6427 - val_loss: 5.4767 - val_mae: 5.4767\n",
            "Epoch 5/100\n",
            "312/312 [==============================] - 1s 4ms/step - loss: 5.6012 - mae: 5.6012 - val_loss: 5.4463 - val_mae: 5.4463\n",
            "Epoch 6/100\n",
            "312/312 [==============================] - 1s 4ms/step - loss: 5.5878 - mae: 5.5878 - val_loss: 5.2957 - val_mae: 5.2957\n",
            "Epoch 7/100\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 5.6606 - mae: 5.6606 - val_loss: 5.3105 - val_mae: 5.3105\n",
            "Epoch 8/100\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 5.6243 - mae: 5.6243 - val_loss: 5.3112 - val_mae: 5.3112\n",
            "Epoch 9/100\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 5.5641 - mae: 5.5641 - val_loss: 5.4519 - val_mae: 5.4519\n",
            "Epoch 10/100\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 5.6064 - mae: 5.6064 - val_loss: 5.3330 - val_mae: 5.3330\n",
            "Epoch 11/100\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 5.6378 - mae: 5.6378 - val_loss: 5.3047 - val_mae: 5.3047\n",
            "Epoch 12/100\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 5.6160 - mae: 5.6160 - val_loss: 5.3876 - val_mae: 5.3876\n",
            "Epoch 13/100\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 5.6486 - mae: 5.6486 - val_loss: 5.3426 - val_mae: 5.3426\n",
            "Epoch 14/100\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 5.6281 - mae: 5.6281 - val_loss: 5.3837 - val_mae: 5.3837\n",
            "Epoch 15/100\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 5.6244 - mae: 5.6244 - val_loss: 5.2903 - val_mae: 5.2903\n",
            "Epoch 16/100\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 5.6000 - mae: 5.6000 - val_loss: 5.2605 - val_mae: 5.2605\n",
            "Epoch 17/100\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 5.6066 - mae: 5.6066 - val_loss: 5.3977 - val_mae: 5.3977\n",
            "Epoch 18/100\n",
            "312/312 [==============================] - 1s 4ms/step - loss: 5.5690 - mae: 5.5690 - val_loss: 5.3536 - val_mae: 5.3536\n",
            "Epoch 19/100\n",
            "312/312 [==============================] - 1s 4ms/step - loss: 5.5997 - mae: 5.5997 - val_loss: 5.9149 - val_mae: 5.9149\n",
            "Epoch 20/100\n",
            "312/312 [==============================] - 1s 4ms/step - loss: 5.6237 - mae: 5.6237 - val_loss: 5.6033 - val_mae: 5.6033\n",
            "Epoch 21/100\n",
            "312/312 [==============================] - 1s 2ms/step - loss: 5.6301 - mae: 5.6301 - val_loss: 5.2674 - val_mae: 5.2674\n",
            "Epoch 22/100\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 5.5711 - mae: 5.5711 - val_loss: 5.3729 - val_mae: 5.3729\n",
            "Epoch 23/100\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 5.5721 - mae: 5.5721 - val_loss: 5.4675 - val_mae: 5.4675\n",
            "Epoch 24/100\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 5.5814 - mae: 5.5814 - val_loss: 5.3681 - val_mae: 5.3681\n",
            "Epoch 25/100\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 5.5861 - mae: 5.5861 - val_loss: 5.2740 - val_mae: 5.2740\n",
            "Epoch 26/100\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 5.5927 - mae: 5.5927 - val_loss: 5.3605 - val_mae: 5.3605\n",
            "95/95 [==============================] - 0s 1ms/step\n",
            "Epoch 1/100\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 246.6819 - mae: 246.6819 - val_loss: 233.1429 - val_mae: 233.1429\n",
            "Epoch 2/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 219.4900 - mae: 219.4900 - val_loss: 183.5651 - val_mae: 183.5651\n",
            "Epoch 3/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 119.4937 - mae: 119.4937 - val_loss: 43.9967 - val_mae: 43.9967\n",
            "Epoch 4/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 17.5546 - mae: 17.5546 - val_loss: 5.1019 - val_mae: 5.1019\n",
            "Epoch 5/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 5.3559 - mae: 5.3559 - val_loss: 4.4596 - val_mae: 4.4596\n",
            "Epoch 6/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 5.2739 - mae: 5.2739 - val_loss: 4.5305 - val_mae: 4.5305\n",
            "Epoch 7/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 5.2270 - mae: 5.2270 - val_loss: 5.2155 - val_mae: 5.2155\n",
            "Epoch 8/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 5.2102 - mae: 5.2102 - val_loss: 4.5558 - val_mae: 4.5558\n",
            "Epoch 9/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 5.1001 - mae: 5.1001 - val_loss: 4.8612 - val_mae: 4.8612\n",
            "Epoch 10/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 5.2028 - mae: 5.2028 - val_loss: 4.5089 - val_mae: 4.5089\n",
            "Epoch 11/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 5.1953 - mae: 5.1953 - val_loss: 4.5260 - val_mae: 4.5260\n",
            "Epoch 12/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 5.2578 - mae: 5.2578 - val_loss: 4.4735 - val_mae: 4.4735\n",
            "Epoch 13/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 5.1816 - mae: 5.1816 - val_loss: 4.4587 - val_mae: 4.4587\n",
            "Epoch 14/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 5.2158 - mae: 5.2158 - val_loss: 4.8014 - val_mae: 4.8014\n",
            "Epoch 15/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 5.2414 - mae: 5.2414 - val_loss: 4.4231 - val_mae: 4.4231\n",
            "Epoch 16/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 5.1765 - mae: 5.1765 - val_loss: 4.6876 - val_mae: 4.6876\n",
            "Epoch 17/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 5.3104 - mae: 5.3104 - val_loss: 4.4921 - val_mae: 4.4921\n",
            "Epoch 18/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 5.2378 - mae: 5.2378 - val_loss: 4.5069 - val_mae: 4.5069\n",
            "Epoch 19/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 5.2563 - mae: 5.2563 - val_loss: 4.5148 - val_mae: 4.5148\n",
            "Epoch 20/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 5.1928 - mae: 5.1928 - val_loss: 4.7860 - val_mae: 4.7860\n",
            "Epoch 21/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 5.1277 - mae: 5.1277 - val_loss: 4.4541 - val_mae: 4.4541\n",
            "Epoch 22/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 5.2732 - mae: 5.2732 - val_loss: 4.6359 - val_mae: 4.6359\n",
            "Epoch 23/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 5.2736 - mae: 5.2736 - val_loss: 4.6397 - val_mae: 4.6397\n",
            "Epoch 24/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 5.2337 - mae: 5.2337 - val_loss: 4.7593 - val_mae: 4.7593\n",
            "Epoch 25/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 5.1886 - mae: 5.1886 - val_loss: 4.4285 - val_mae: 4.4285\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "Overall R^2 for Neural Network: 0.9856599174819396\n",
            "Overall MAE for Neural Network: 14.23692951103783\n",
            "    stop_sequence day_type       R^2        MAE\n",
            "0               1  weekday  0.886193  27.748052\n",
            "1               1  weekend  0.948908  26.286622\n",
            "2               5  weekday  0.976773  14.467879\n",
            "3               5  weekend  0.991135  11.500138\n",
            "4               8  weekday  0.981007  15.621969\n",
            "5               8  weekend  0.991809  12.832557\n",
            "6              12  weekday  0.989743  11.615029\n",
            "7              12  weekend  0.995278  10.232191\n",
            "8              14  weekday  0.986556  14.728167\n",
            "9              14  weekend  0.991868  15.497516\n",
            "10             16  weekday  0.975506  20.377205\n",
            "11             16  weekend  0.991591  15.229881\n",
            "12             20  weekday  0.994473   9.221530\n",
            "13             20  weekend  0.997634   7.514777\n",
            "14             21  weekday  0.991804  12.831240\n",
            "15             21  weekend  0.995665  11.097480\n",
            "16             23  weekday  0.998498   5.248837\n",
            "17             23  weekend  0.999070   4.714051\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "import joblib\n",
        "import os\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def train_and_evaluate_nn(df):\n",
        "    # Split the dataset into training and test sets\n",
        "    df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "    if df_train.empty or df_test.empty:\n",
        "        print(\"Training or testing dataset is empty.\")\n",
        "        return None  # Return early if the dataset is empty\n",
        "\n",
        "    sc = StandardScaler()\n",
        "\n",
        "    y_mean = df_test['arrival_delay'].mean()\n",
        "    overall_ssr = 0  # Initialize overall_ssr\n",
        "    overall_tss = 0  # Initialize overall_tss\n",
        "    overall_mae_sum = 0  # Initialize overall MAE sum\n",
        "    total_predictions = 0  # Initialize total predictions\n",
        "\n",
        "    results = {\n",
        "        'stop_sequence': [],\n",
        "        'day_type': [],\n",
        "        'R^2': [],\n",
        "        'MAE': []\n",
        "    }\n",
        "\n",
        "    for stop_seq in df['stop_sequence'].unique():\n",
        "        for day_type in ['weekday', 'weekend']:\n",
        "            # Filter data\n",
        "            df_train_subset = df_train[(df_train['stop_sequence'] == stop_seq) & (df_train['day_of_week'] == day_type)]\n",
        "            df_test_subset = df_test[(df_test['stop_sequence'] == stop_seq) & (df_test['day_of_week'] == day_type)]\n",
        "\n",
        "            # Prepare data\n",
        "            x_train = df_train_subset.drop(['arrival_delay', 'day_of_week'], axis=1)\n",
        "            y_train = df_train_subset['arrival_delay']\n",
        "\n",
        "            x_test = df_test_subset.drop(['arrival_delay', 'day_of_week'], axis=1)\n",
        "            y_test = df_test_subset['arrival_delay']\n",
        "\n",
        "            # Normalize the input features\n",
        "            x_train = sc.fit_transform(x_train)\n",
        "            x_test = sc.transform(x_test)\n",
        "\n",
        "            # Neural network model\n",
        "            model = Sequential()\n",
        "            model.add(Dense(32, activation='linear', input_dim=x_train.shape[1]))\n",
        "            model.add(Dropout(0.001))\n",
        "            model.add(Dense(64, activation='linear'))\n",
        "            model.add(Dense(1))\n",
        "\n",
        "            model.compile(optimizer='adam', loss='mae', metrics=['mae'])\n",
        "\n",
        "            early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "            model.fit(x_train, y_train, validation_split=0.2, epochs=100, batch_size=32, callbacks=[early_stopping], verbose=1)\n",
        "\n",
        "            y_pred = model.predict(x_test).flatten()\n",
        "            current_r2 = r2_score(y_test, y_pred)\n",
        "            current_mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "            residuals = y_test - y_pred\n",
        "            ssr = sum(residuals**2)\n",
        "            overall_ssr += ssr\n",
        "            tss = sum((y_test - y_mean)**2)\n",
        "            overall_tss += tss\n",
        "\n",
        "            total_predictions += len(y_test)\n",
        "            overall_mae_sum += current_mae * len(y_test)\n",
        "\n",
        "            results['stop_sequence'].append(stop_seq)\n",
        "            results['day_type'].append(day_type)\n",
        "            results['R^2'].append(current_r2)\n",
        "            results['MAE'].append(current_mae)\n",
        "\n",
        "    overall_r2 = 1 - (overall_ssr / overall_tss)\n",
        "    overall_mae = overall_mae_sum / total_predictions  # Calculate overall MAE\n",
        "\n",
        "    print(f'Overall R^2 for Neural Network: {overall_r2}')\n",
        "    print(f'Overall MAE for Neural Network: {overall_mae}')\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Example usage:\n",
        "results_df = train_and_evaluate_nn(df_9stops)\n",
        "if results_df is not None:\n",
        "    print(results_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kyMzP8TOVD8I",
      "metadata": {
        "id": "kyMzP8TOVD8I"
      },
      "source": [
        "### Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_9stops.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnoslAqhY_AN",
        "outputId": "fdab5331-a1ea-481b-f83d-81c79e92c9a3"
      },
      "id": "PnoslAqhY_AN",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 181626 entries, 0 to 545098\n",
            "Data columns (total 12 columns):\n",
            " #   Column                            Non-Null Count   Dtype  \n",
            "---  ------                            --------------   -----  \n",
            " 0   stop_sequence                     181626 non-null  int64  \n",
            " 1   arrival_delay                     181626 non-null  int64  \n",
            " 2   dwell_time                        181626 non-null  int64  \n",
            " 3   travel_time_for_previous_section  181626 non-null  int64  \n",
            " 4   scheduled_travel_time             181626 non-null  int64  \n",
            " 5   upstream_stop_delay               181626 non-null  int64  \n",
            " 6   origin_delay                      181626 non-null  int64  \n",
            " 7   previous_bus_delay                181626 non-null  int64  \n",
            " 8   previous_trip_travel_time         181626 non-null  int64  \n",
            " 9   traffic_condition                 181626 non-null  float64\n",
            " 10  recurrent_delay                   181626 non-null  float64\n",
            " 11  day_of_week                       181626 non-null  object \n",
            "dtypes: float64(2), int64(9), object(1)\n",
            "memory usage: 18.0+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "Len0ocwcVGjx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Len0ocwcVGjx",
        "outputId": "6dd7d1dc-e339-40ea-e9e8-00f854dea856"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall R^2: 0.986543559614433\n",
            "Overall MAE: 14.639100285929766\n",
            "    stop_sequence day_type       R^2        MAE\n",
            "0               1  weekday  0.895897  29.206868\n",
            "1               1  weekend  0.950604  27.460467\n",
            "2               5  weekday  0.977695  14.720359\n",
            "3               5  weekend  0.991448  11.532659\n",
            "4               8  weekday  0.981402  15.946810\n",
            "5               8  weekend  0.991961  12.834797\n",
            "6              12  weekday  0.990878  12.361416\n",
            "7              12  weekend  0.995921  10.499564\n",
            "8              14  weekday  0.987187  14.936114\n",
            "9              14  weekend  0.992177  15.715836\n",
            "10             16  weekday  0.977038  20.886223\n",
            "11             16  weekend  0.992190  15.197998\n",
            "12             20  weekday  0.994707   9.459281\n",
            "13             20  weekend  0.997881   7.699327\n",
            "14             21  weekday  0.992222  13.044044\n",
            "15             21  weekend  0.995861  11.226847\n",
            "16             23  weekday  0.998542   5.370143\n",
            "17             23  weekend  0.999086   4.747134\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.feature_selection import RFECV\n",
        "\n",
        "def train_and_evaluate(df):\n",
        "    # Split the entire dataset into training and test sets\n",
        "    df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "    y_mean = df_test['arrival_delay'].mean()\n",
        "\n",
        "    results = {\n",
        "        'stop_sequence': [],\n",
        "        'day_type': [],\n",
        "        'R^2': [],\n",
        "        'MAE': []\n",
        "    }\n",
        "\n",
        "    weighted_mae_sum = 0\n",
        "    total_samples = 0\n",
        "    overall_ssr = 0\n",
        "    overall_tss = 0\n",
        "\n",
        "    for stop_seq in df['stop_sequence'].unique():\n",
        "        for day_type in ['weekday', 'weekend']:\n",
        "            # Filter data by stop sequence and day type\n",
        "            df_train_subset = df_train[(df_train['stop_sequence'] == stop_seq) & (df_train['day_of_week'] == day_type)]\n",
        "            df_test_subset = df_test[(df_test['stop_sequence'] == stop_seq) & (df_test['day_of_week'] == day_type)]\n",
        "\n",
        "            # Train model with RFECV\n",
        "            x_train = df_train_subset.drop(['arrival_delay', 'day_of_week'], axis=1)\n",
        "            y_train = df_train_subset['arrival_delay']\n",
        "\n",
        "            model = LinearRegression()\n",
        "            selector = RFECV(estimator=model, step=1, cv=KFold(5))\n",
        "            selector = selector.fit(x_train, y_train)\n",
        "\n",
        "            # Fit model with selected features\n",
        "            model.fit(x_train.iloc[:, selector.support_], y_train)\n",
        "\n",
        "            # Evaluate the model\n",
        "            x_test = df_test_subset.drop(['arrival_delay', 'day_of_week'], axis=1).iloc[:, selector.support_]\n",
        "            y_test = df_test_subset['arrival_delay']\n",
        "\n",
        "            y_pred = model.predict(x_test)\n",
        "            mae = mean_absolute_error(y_test, y_pred)\n",
        "            r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "            sample_count = len(y_test)\n",
        "            weighted_mae_sum += mae * sample_count\n",
        "            total_samples += sample_count\n",
        "\n",
        "            residuals = y_test - y_pred\n",
        "            ssr = sum(residuals**2)\n",
        "            overall_ssr += ssr\n",
        "            tss = sum((y_test - y_mean)**2)\n",
        "            overall_tss += tss\n",
        "\n",
        "            results['stop_sequence'].append(stop_seq)\n",
        "            results['day_type'].append(day_type)\n",
        "            results['R^2'].append(r2)\n",
        "            results['MAE'].append(mae)\n",
        "\n",
        "\n",
        "    overall_r2 = 1 - (overall_ssr / overall_tss)\n",
        "    overall_mae = weighted_mae_sum / total_samples\n",
        "\n",
        "    print(f'Overall R^2: {overall_r2}')\n",
        "    print(f'Overall MAE: {overall_mae}')\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Example usage:\n",
        "results_df = train_and_evaluate(df_9stops)\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LR VS NN"
      ],
      "metadata": {
        "id": "ITwytOSO2wyv"
      },
      "id": "ITwytOSO2wyv"
    },
    {
      "cell_type": "code",
      "source": [
        "df_9stops.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VojcOhjEfU1M",
        "outputId": "ba54f094-a08b-4026-ba97-88fcd08152fe"
      },
      "id": "VojcOhjEfU1M",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 181626 entries, 0 to 545098\n",
            "Data columns (total 12 columns):\n",
            " #   Column                            Non-Null Count   Dtype  \n",
            "---  ------                            --------------   -----  \n",
            " 0   stop_sequence                     181626 non-null  int64  \n",
            " 1   arrival_delay                     181626 non-null  int64  \n",
            " 2   dwell_time                        181626 non-null  int64  \n",
            " 3   travel_time_for_previous_section  181626 non-null  int64  \n",
            " 4   scheduled_travel_time             181626 non-null  int64  \n",
            " 5   upstream_stop_delay               181626 non-null  int64  \n",
            " 6   origin_delay                      181626 non-null  int64  \n",
            " 7   previous_bus_delay                181626 non-null  int64  \n",
            " 8   previous_trip_travel_time         181626 non-null  int64  \n",
            " 9   traffic_condition                 181626 non-null  float64\n",
            " 10  recurrent_delay                   181626 non-null  float64\n",
            " 11  day_of_week                       181626 non-null  object \n",
            "dtypes: float64(2), int64(9), object(1)\n",
            "memory usage: 18.0+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "def train_evaluate_best_model(df, n_folds=5):\n",
        "\n",
        "    df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "    results = {\n",
        "        'stop_sequence': [],\n",
        "        'day_type': [],\n",
        "        'best_model': [],\n",
        "        'R^2': [],\n",
        "        'MAE': []\n",
        "    }\n",
        "\n",
        "    overall_r2_values = []\n",
        "    overall_sample_weights = []\n",
        "\n",
        "    for stop_seq in df['stop_sequence'].unique():\n",
        "        for day_type in ['weekday', 'weekend']:\n",
        "            df_train_subset = df_train[(df_train['stop_sequence'] == stop_seq) & (df_train['day_of_week'] == day_type)]\n",
        "            df_test_subset = df_test[(df_test['stop_sequence'] == stop_seq) & (df_test['day_of_week'] == day_type)]\n",
        "\n",
        "            drop_columns = ['arrival_delay', 'day_of_week']\n",
        "            x_train = df_train_subset.drop(columns=drop_columns, errors='ignore').astype('float32')\n",
        "            y_train = df_train_subset['arrival_delay'].astype('float32')\n",
        "            x_test = df_test_subset.drop(columns=drop_columns, errors='ignore').astype('float32')\n",
        "            y_test = df_test_subset['arrival_delay'].astype('float32')\n",
        "\n",
        "            r2_scores_nn = []\n",
        "            r2_scores_lr = []\n",
        "            maes_nn = []\n",
        "            maes_lr = []\n",
        "\n",
        "            # K-fold CV\n",
        "            kf = KFold(n_splits=n_folds)\n",
        "            for train_index, val_index in kf.split(x_train):\n",
        "                x_train_fold, x_val_fold = x_train.iloc[train_index], x_train.iloc[val_index]\n",
        "                y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
        "\n",
        "                # Train and evaluate NN\n",
        "                model_nn = Sequential([\n",
        "                    Dense(32, activation='linear', input_dim=x_train_fold.shape[1]),\n",
        "                    Dropout(0.001),\n",
        "                    Dense(64, activation='linear'),\n",
        "                    Dense(1)\n",
        "                ])\n",
        "                model_nn.compile(optimizer='adam', loss='mae', metrics=['mae'])\n",
        "                early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "                model_nn.fit(x_train_fold, y_train_fold, validation_data=(x_val_fold, y_val_fold), epochs=100, batch_size=32, callbacks=[early_stopping], verbose=0)\n",
        "                y_pred_nn = model_nn.predict(x_val_fold).flatten()\n",
        "                r2_scores_nn.append(r2_score(y_val_fold, y_pred_nn))\n",
        "                maes_nn.append(mean_absolute_error(y_val_fold, y_pred_nn))\n",
        "\n",
        "                # Train and evaluate LR\n",
        "                model_lr = LinearRegression().fit(x_train_fold, y_train_fold)\n",
        "                y_pred_lr = model_lr.predict(x_val_fold)\n",
        "                r2_scores_lr.append(r2_score(y_val_fold, y_pred_lr))\n",
        "                maes_lr.append(mean_absolute_error(y_val_fold, y_pred_lr))\n",
        "\n",
        "            # Average scores\n",
        "            avg_r2_nn = np.mean(r2_scores_nn)\n",
        "            avg_r2_lr = np.mean(r2_scores_lr)\n",
        "            avg_mae_nn = np.mean(maes_nn)\n",
        "            avg_mae_lr = np.mean(maes_lr)\n",
        "\n",
        "            # Determine best model\n",
        "            if avg_r2_nn > avg_r2_lr:\n",
        "                best_model = \"NN\"\n",
        "                best_r2 = avg_r2_nn\n",
        "                best_mae = avg_mae_nn\n",
        "            else:\n",
        "                best_model = \"LR\"\n",
        "                best_r2 = avg_r2_lr\n",
        "                best_mae = avg_mae_lr\n",
        "\n",
        "            # Save models\n",
        "            model_dir = \"models\"\n",
        "            if not os.path.exists(model_dir):\n",
        "                os.makedirs(model_dir)\n",
        "            if best_model == \"NN\":\n",
        "                model_nn.save(os.path.join(model_dir, f'nn_model_{stop_seq}_{day_type}.h5'))\n",
        "            else:\n",
        "                joblib.dump(model_lr, os.path.join(model_dir, f'lr_model_{stop_seq}_{day_type}.pkl'))\n",
        "\n",
        "            overall_r2_values.append(best_r2)\n",
        "            overall_sample_weights.append(len(df_test_subset))\n",
        "            results['stop_sequence'].append(stop_seq)\n",
        "            results['day_type'].append(day_type)\n",
        "            results['best_model'].append(best_model)\n",
        "            results['R^2'].append(best_r2)\n",
        "            results['MAE'].append(best_mae)\n",
        "\n",
        "    overall_r2 = np.average(overall_r2_values, weights=overall_sample_weights)\n",
        "    print(f\"Overall R^2: {overall_r2:.2f}\")\n",
        "\n",
        "    overall_mae = np.average(results['MAE'], weights = overall_sample_weights)\n",
        "    print(f\"Overall MAE: {overall_mae:.2f}\")\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# predict_new_data function remains mostly the same.\n",
        "def predict_new_data(df_9stops):\n",
        "    all_groups = []  # Placeholder for updated groups\n",
        "\n",
        "    # Group the dataframe by 'stop_sequence' and 'day_of_week'\n",
        "    grouped = df.groupby(['stop_sequence', 'day_of_week'])\n",
        "\n",
        "    for (stop_seq, day_type), group in grouped:\n",
        "        nn_model_path = os.path.join(\"models\", f'nn_model_{stop_seq}_{day_type}.h5')\n",
        "        lr_model_path = os.path.join(\"models\", f'lr_model_{stop_seq}_{day_type}.pkl')\n",
        "\n",
        "        X = group.drop(columns=['arrival_delay', 'day_of_week'], errors='ignore').astype('float32')\n",
        "\n",
        "        if os.path.exists(nn_model_path):\n",
        "            model = load_model(nn_model_path)\n",
        "            group['predicted_delay'] = model.predict(X).flatten()\n",
        "\n",
        "        elif os.path.exists(lr_model_path):\n",
        "            model = joblib.load(lr_model_path)\n",
        "            group['predicted_delay'] = model.predict(X)\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"No saved model found for stop_sequence: {stop_seq} and day_type: {day_type}\")\n",
        "\n",
        "        all_groups.append(group)\n",
        "\n",
        "    # Concatenate all updated groups to get the final dataframe\n",
        "    result_df = pd.concat(all_groups)\n",
        "\n",
        "    return result_df"
      ],
      "metadata": {
        "id": "m84H9YMEJskE"
      },
      "id": "m84H9YMEJskE",
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = train_evaluate_best_model(df_9stops)\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgtW7xYAKkeV",
        "outputId": "d13788e1-3802-418f-a590-5f3d845296dc"
      },
      "id": "CgtW7xYAKkeV",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "78/78 [==============================] - 1s 2ms/step\n",
            "78/78 [==============================] - 0s 1ms/step\n",
            "78/78 [==============================] - 0s 1ms/step\n",
            "78/78 [==============================] - 0s 1ms/step\n",
            "78/78 [==============================] - 0s 2ms/step\n",
            "24/24 [==============================] - 0s 1ms/step\n",
            "24/24 [==============================] - 0s 2ms/step\n",
            "24/24 [==============================] - 0s 2ms/step\n",
            "24/24 [==============================] - 0s 2ms/step\n",
            "24/24 [==============================] - 0s 1ms/step\n",
            "78/78 [==============================] - 0s 3ms/step\n",
            "78/78 [==============================] - 0s 2ms/step\n",
            "78/78 [==============================] - 0s 1ms/step\n",
            "78/78 [==============================] - 0s 1ms/step\n",
            "78/78 [==============================] - 0s 2ms/step\n",
            "24/24 [==============================] - 0s 2ms/step\n",
            "24/24 [==============================] - 0s 2ms/step\n",
            "24/24 [==============================] - 0s 3ms/step\n",
            "24/24 [==============================] - 0s 2ms/step\n",
            "24/24 [==============================] - 0s 2ms/step\n",
            "78/78 [==============================] - 0s 1ms/step\n",
            "78/78 [==============================] - 0s 1ms/step\n",
            "78/78 [==============================] - 0s 2ms/step\n",
            "78/78 [==============================] - 0s 2ms/step\n",
            "78/78 [==============================] - 0s 1ms/step\n",
            "24/24 [==============================] - 0s 2ms/step\n",
            "24/24 [==============================] - 0s 2ms/step\n",
            "24/24 [==============================] - 0s 3ms/step\n",
            "24/24 [==============================] - 0s 2ms/step\n",
            "24/24 [==============================] - 0s 1ms/step\n",
            "78/78 [==============================] - 0s 2ms/step\n",
            "78/78 [==============================] - 0s 1ms/step\n",
            "78/78 [==============================] - 0s 1ms/step\n",
            "78/78 [==============================] - 0s 1ms/step\n",
            "78/78 [==============================] - 0s 2ms/step\n",
            "24/24 [==============================] - 0s 2ms/step\n",
            "24/24 [==============================] - 0s 1ms/step\n",
            "24/24 [==============================] - 0s 1ms/step\n",
            "24/24 [==============================] - 0s 2ms/step\n",
            "24/24 [==============================] - 0s 2ms/step\n",
            "78/78 [==============================] - 0s 2ms/step\n",
            "78/78 [==============================] - 0s 1ms/step\n",
            "78/78 [==============================] - 0s 1ms/step\n",
            "78/78 [==============================] - 0s 1ms/step\n",
            "78/78 [==============================] - 0s 2ms/step\n",
            "24/24 [==============================] - 0s 2ms/step\n",
            "24/24 [==============================] - 0s 2ms/step\n",
            "24/24 [==============================] - 0s 2ms/step\n",
            "24/24 [==============================] - 0s 2ms/step\n",
            "24/24 [==============================] - 0s 2ms/step\n",
            "78/78 [==============================] - 0s 2ms/step\n",
            "78/78 [==============================] - 0s 1ms/step\n",
            "78/78 [==============================] - 0s 2ms/step\n",
            "78/78 [==============================] - 0s 2ms/step\n",
            "78/78 [==============================] - 0s 2ms/step\n",
            "24/24 [==============================] - 0s 2ms/step\n",
            "24/24 [==============================] - 0s 2ms/step\n",
            "24/24 [==============================] - 0s 2ms/step\n",
            "24/24 [==============================] - 0s 1ms/step\n",
            "24/24 [==============================] - 0s 2ms/step\n",
            "77/77 [==============================] - 0s 2ms/step\n",
            "77/77 [==============================] - 0s 1ms/step\n",
            "77/77 [==============================] - 0s 1ms/step\n",
            "77/77 [==============================] - 0s 1ms/step\n",
            "77/77 [==============================] - 0s 2ms/step\n",
            "24/24 [==============================] - 0s 2ms/step\n",
            "24/24 [==============================] - 0s 1ms/step\n",
            "24/24 [==============================] - 0s 2ms/step\n",
            "24/24 [==============================] - 0s 3ms/step\n",
            "24/24 [==============================] - 0s 1ms/step\n",
            "78/78 [==============================] - 0s 2ms/step\n",
            "78/78 [==============================] - 0s 1ms/step\n",
            "78/78 [==============================] - 0s 2ms/step\n",
            "78/78 [==============================] - 0s 1ms/step\n",
            "78/78 [==============================] - 0s 1ms/step\n",
            "24/24 [==============================] - 0s 1ms/step\n",
            "24/24 [==============================] - 0s 1ms/step\n",
            "24/24 [==============================] - 0s 2ms/step\n",
            "24/24 [==============================] - 0s 1ms/step\n",
            "24/24 [==============================] - 0s 3ms/step\n",
            "78/78 [==============================] - 0s 1ms/step\n",
            "78/78 [==============================] - 0s 1ms/step\n",
            "78/78 [==============================] - 0s 2ms/step\n",
            "78/78 [==============================] - 0s 2ms/step\n",
            "78/78 [==============================] - 0s 2ms/step\n",
            "24/24 [==============================] - 0s 3ms/step\n",
            "24/24 [==============================] - 0s 2ms/step\n",
            "24/24 [==============================] - 0s 1ms/step\n",
            "24/24 [==============================] - 0s 1ms/step\n",
            "24/24 [==============================] - 0s 2ms/step\n",
            "Overall R^2: 0.98\n",
            "Overall MAE: 14.53\n",
            "    stop_sequence day_type best_model       R^2        MAE\n",
            "0               1  weekday         LR  0.903063  28.628769\n",
            "1               1  weekend         LR  0.957562  27.048279\n",
            "2               5  weekday         LR  0.978734  14.499735\n",
            "3               5  weekend         LR  0.992105  11.614477\n",
            "4               8  weekday         LR  0.976778  16.405163\n",
            "5               8  weekend         LR  0.992977  12.610491\n",
            "6              12  weekday         LR  0.990813  12.240393\n",
            "7              12  weekend         LR  0.995987  10.468593\n",
            "8              14  weekday         LR  0.987009  14.920743\n",
            "9              14  weekend         LR  0.991046  16.113323\n",
            "10             16  weekday         LR  0.975959  20.235369\n",
            "11             16  weekend         LR  0.992163  14.783974\n",
            "12             20  weekday         LR  0.995011   9.325909\n",
            "13             20  weekend         LR  0.997587   8.078837\n",
            "14             21  weekday         LR  0.992098  13.090871\n",
            "15             21  weekend         LR  0.996406  10.908302\n",
            "16             23  weekday         LR  0.998330   5.412032\n",
            "17             23  weekend         LR  0.999159   4.759795\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}