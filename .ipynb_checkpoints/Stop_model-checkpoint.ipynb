{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76714239",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Plot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "import calendar \n",
    "import calplot # actually used\n",
    "\n",
    "# Score model\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Model\n",
    "from sklearn.model_selection import train_test_split, cross_val_score,GridSearchCV\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from scipy import stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1e304c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers removed: 228\n",
      "Size of the original DataFrame: 544875\n"
     ]
    }
   ],
   "source": [
    "# Read the data\n",
    "url = \"https://raw.githubusercontent.com/zhenliangma/Applied-AI-in-Transportation/main/ProjectAssignmentData/Dataset-PT.csv\"\n",
    "df = pd.read_csv(url, header=1)\n",
    "#df = df.drop(columns=['weather', 'temperature', 'day_of_week', 'time_of_day'])\n",
    "# Calculate z-scores for the 'arrival_delay' column\n",
    "z_scores = stats.zscore(df['arrival_delay'])\n",
    "\n",
    "# Get boolean array indicating the location of outliers\n",
    "outliers = (z_scores > 7) | (z_scores < -7)\n",
    "\n",
    "# Count the number of outliers\n",
    "num_outliers = outliers.sum()\n",
    "\n",
    "# Print the number of outliers\n",
    "print(f\"Number of outliers removed: {num_outliers}\")\n",
    "\n",
    "# Remove the outliers\n",
    "df = df[~outliers]\n",
    "\n",
    "# Verify the new size of the DataFrame\n",
    "print(f\"Size of the original DataFrame: {len(df)}\")\n",
    "#print(f\"Size of the DataFrame after removing outliers: {len(df_no_outliers)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a884bc",
   "metadata": {},
   "source": [
    "# stop and daytime models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9fdf58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall R^2: 0.989619067772344\n",
      "Overall MAE: 12.228547173116066\n",
      "    stop_sequence day_type       R^2        MAE\n",
      "0               1  weekday  0.907789  28.079150\n",
      "1               1  weekend  0.945927  28.133992\n",
      "2               2  weekday  0.994341   7.961897\n",
      "3               2  weekend  0.996451   7.032571\n",
      "4               3  weekday  0.994364   7.562599\n",
      "5               3  weekend  0.997188   6.564969\n",
      "6               4  weekday  0.969525  18.877087\n",
      "7               4  weekend  0.989087  11.836640\n",
      "8               5  weekday  0.979133  14.260601\n",
      "9               5  weekend  0.993399  11.236295\n",
      "10              6  weekday  0.988645  13.048595\n",
      "11              6  weekend  0.993592  12.180406\n",
      "12              7  weekday  0.991089  10.166501\n",
      "13              7  weekend  0.995717   9.197009\n",
      "14              8  weekday  0.979640  16.051619\n",
      "15              8  weekend  0.993770  12.026367\n",
      "16              9  weekday  0.994514   8.123681\n",
      "17              9  weekend  0.997754   6.787489\n",
      "18             10  weekday  0.992584   9.974717\n",
      "19             10  weekend  0.996835   8.387752\n",
      "20             11  weekday  0.985192  16.260256\n",
      "21             11  weekend  0.994672  12.165961\n",
      "22             12  weekday  0.990543  12.154205\n",
      "23             12  weekend  0.995569  10.446174\n",
      "24             13  weekday  0.984427  15.158210\n",
      "25             13  weekend  0.968408  15.139938\n",
      "26             14  weekday  0.985871  15.208541\n",
      "27             14  weekend  0.991506  15.670781\n",
      "28             15  weekday  0.994939   6.915116\n",
      "29             15  weekend  0.998382   6.651905\n",
      "30             16  weekday  0.975115  20.223121\n",
      "31             16  weekend  0.992342  14.921954\n",
      "32             17  weekday  0.978069  18.146161\n",
      "33             17  weekend  0.994967  10.505434\n",
      "34             18  weekday  0.971713  21.915717\n",
      "35             18  weekend  0.988226  18.809726\n",
      "36             19  weekday  0.995652   8.098602\n",
      "37             19  weekend  0.997757   6.920834\n",
      "38             20  weekday  0.994848   9.511890\n",
      "39             20  weekend  0.997438   8.224047\n",
      "40             21  weekday  0.991552  12.958672\n",
      "41             21  weekend  0.996459  11.166504\n",
      "42             22  weekday  0.993169  11.607246\n",
      "43             22  weekend  0.997676   8.472129\n",
      "44             23  weekday  0.998471   5.311370\n",
      "45             23  weekend  0.999146   4.768241\n",
      "46             24  weekday  0.995647  10.122244\n",
      "47             24  weekend  0.997227   9.597449\n",
      "48             25  weekday  0.998093   6.624192\n",
      "49             25  weekend  0.999123   5.451588\n",
      "50             26  weekday  0.996501   8.876780\n",
      "51             26  weekend  0.999041   5.503768\n",
      "52             27  weekday  0.975733  10.094162\n",
      "53             27  weekend  0.976393  10.549976\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "def train_and_evaluate(df):\n",
    "    # Split the entire dataset into training and test sets\n",
    "    df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "    y_mean = df_test['arrival_delay'].mean()\n",
    "\n",
    "    results = {\n",
    "        'stop_sequence': [],\n",
    "        'day_type': [],\n",
    "        'R^2': [],\n",
    "        'MAE': []\n",
    "    }\n",
    "\n",
    "    weighted_mae_sum = 0\n",
    "    total_samples = 0\n",
    "    overall_ssr = 0\n",
    "    overall_tss = 0\n",
    "\n",
    "    for stop_seq in df['stop_sequence'].unique():\n",
    "        for day_type in ['weekday', 'weekend']:\n",
    "            # Filter data by stop sequence and day type\n",
    "            df_train_subset = df_train[(df_train['stop_sequence'] == stop_seq) & (df_train['day_of_week'] == day_type)]\n",
    "            df_test_subset = df_test[(df_test['stop_sequence'] == stop_seq) & (df_test['day_of_week'] == day_type)]\n",
    "\n",
    "            # Train model with RFECV\n",
    "            x_train = df_train_subset.drop(['arrival_delay', 'day_of_week', 'time_of_day', \"weather\", \"temperature\"], axis=1)\n",
    "            y_train = df_train_subset['arrival_delay']\n",
    "\n",
    "            model = LinearRegression()\n",
    "            selector = RFECV(estimator=model, step=1, cv=KFold(5))\n",
    "            selector = selector.fit(x_train, y_train)\n",
    "            \n",
    "            # Fit model with selected features\n",
    "            model.fit(x_train.iloc[:, selector.support_], y_train)\n",
    "\n",
    "            # Evaluate the model\n",
    "            x_test = df_test_subset.drop(['arrival_delay', 'day_of_week', 'time_of_day', \"weather\", \"temperature\"], axis=1).iloc[:, selector.support_]\n",
    "            \n",
    "            y_test = df_test_subset['arrival_delay']\n",
    "            \n",
    "            y_pred = model.predict(x_test)\n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "            sample_count = len(y_test)\n",
    "            weighted_mae_sum += mae * sample_count\n",
    "            total_samples += sample_count\n",
    "\n",
    "            residuals = y_test - y_pred\n",
    "            ssr = sum(residuals**2)\n",
    "            overall_ssr += ssr\n",
    "            tss = sum((y_test - y_mean)**2)\n",
    "            overall_tss += tss\n",
    "\n",
    "            results['stop_sequence'].append(stop_seq)\n",
    "            results['day_type'].append(day_type)\n",
    "            results['R^2'].append(r2)\n",
    "            results['MAE'].append(mae)\n",
    "            \n",
    "\n",
    "    overall_r2 = 1 - (overall_ssr / overall_tss)\n",
    "    overall_mae = weighted_mae_sum / total_samples\n",
    "\n",
    "    print(f'Overall R^2: {overall_r2}')\n",
    "    print(f'Overall MAE: {overall_mae}')\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Example usage:\n",
    "results_df = train_and_evaluate(df)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c08729",
   "metadata": {},
   "source": [
    "# Only Daytype Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90ab1e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pandas as pd\n",
    "\n",
    "def train_and_evaluate(df):\n",
    "    # Split the dataset\n",
    "    df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Results placeholder\n",
    "    results = {\n",
    "        'day_type': [],\n",
    "        'best_model': [],\n",
    "        'MSE': [],\n",
    "        'MAE': [],\n",
    "        'R^2': []  \n",
    "    }\n",
    "\n",
    "    # Function to train and evaluate Linear Regression with RFECV\n",
    "    def train_lr_model(df_train_subset):\n",
    "        x_train = df_train_subset.drop(['arrival_delay', 'day_of_week', 'time_of_day', \"weather\", \"temperature\"], axis=1)\n",
    "        y_train = df_train_subset['arrival_delay']\n",
    "\n",
    "        model = LinearRegression()\n",
    "        selector = RFECV(estimator=model, step=1, cv=KFold(5))\n",
    "        selector = selector.fit(x_train, y_train)\n",
    "\n",
    "        model.fit(x_train.iloc[:, selector.support_], y_train)\n",
    "        \n",
    "        return model, selector\n",
    "\n",
    "    # Function to train Neural Network\n",
    "    def train_nn_model(df_train_subset):\n",
    "        x_train = df_train_subset.drop(['arrival_delay', 'day_of_week', 'time_of_day', \"weather\", \"temperature\"], axis=1)\n",
    "        y_train = df_train_subset['arrival_delay']\n",
    "\n",
    "        model_nn = Sequential([\n",
    "            Dense(32, activation='relu', input_dim=x_train.shape[1]),\n",
    "            Dropout(0.001),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dense(1)\n",
    "        ])\n",
    "        model_nn.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "        model_nn.fit(x_train, y_train, validation_split=0.2, epochs=100, batch_size=32, callbacks=[early_stopping], verbose=0)\n",
    "        \n",
    "        return model_nn\n",
    "\n",
    "    for day_type in ['weekday', 'weekend']:\n",
    "        df_train_subset = df_train[df_train['day_of_week'] == day_type]\n",
    "        df_test_subset = df_test[df_test['day_of_week'] == day_type]\n",
    "\n",
    "        # Train and evaluate Linear Regression model\n",
    "        model_lr, selector = train_lr_model(df_train_subset)\n",
    "        x_test = df_test_subset.drop(['arrival_delay', 'day_of_week', 'time_of_day', \"weather\", \"temperature\"], axis=1).iloc[:, selector.support_]\n",
    "        y_pred_lr = model_lr.predict(x_test)\n",
    "        mse_lr = mean_squared_error(df_test_subset['arrival_delay'], y_pred_lr)\n",
    "        mae_lr = mean_absolute_error(df_test_subset['arrival_delay'], y_pred_lr)\n",
    "        r2_lr = r2_score(df_test_subset['arrival_delay'], y_pred_lr)\n",
    "        # Train and evaluate Neural Network\n",
    "        model_nn = train_nn_model(df_train_subset)\n",
    "        y_pred_nn = model_nn.predict(df_test_subset.drop(['arrival_delay', 'day_of_week', 'time_of_day', \"weather\", \"temperature\"], axis=1)).flatten()\n",
    "        mse_nn = mean_squared_error(df_test_subset['arrival_delay'], y_pred_nn)\n",
    "        mae_nn = mean_absolute_error(df_test_subset['arrival_delay'], y_pred_nn)\n",
    "        r2_nn = r2_score(df_test_subset['arrival_delay'], y_pred_nn)\n",
    "\n",
    "        # Choose the best model based on MAE\n",
    "        if mae_nn < mae_lr:\n",
    "            best_model = \"NN\"\n",
    "            best_mse = mse_nn\n",
    "            best_mae = mae_nn\n",
    "            best_r2 = r2_nn\n",
    "        else:\n",
    "            best_model = \"LR\"\n",
    "            best_mse = mse_lr\n",
    "            best_mae = mae_lr\n",
    "            best_r2 = r2_lr\n",
    "\n",
    "        results['day_type'].append(day_type)\n",
    "        results['best_model'].append(best_model)\n",
    "        results['MSE'].append(best_mse)\n",
    "        results['MAE'].append(best_mae)\n",
    "        results['R^2'].append(best_r2)\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Example usage:\n",
    "# df = ...  # Your dataframe\n",
    "# result_df = train_and_evaluate(df)\n",
    "# print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7650a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2612/2612 [==============================] - 5s 2ms/step\n",
      "795/795 [==============================] - 2s 3ms/step\n",
      "  day_type best_model         MSE        MAE       R^2\n",
      "0  weekday         LR  403.634672  13.013826  0.986993\n",
      "1  weekend         LR  343.030509  11.043053  0.992785\n"
     ]
    }
   ],
   "source": [
    "results = train_and_evaluate(df)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eed627e",
   "metadata": {},
   "source": [
    "# NN VS LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b245a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09fab492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "def train_evaluate_best_model(df, n_folds=5):\n",
    "\n",
    "    df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "    results = {\n",
    "        'stop_sequence': [],\n",
    "        'day_type': [],\n",
    "        'best_model': [],\n",
    "        'R^2': [],\n",
    "        'MAE': []\n",
    "    }\n",
    "\n",
    "    overall_r2_values = []\n",
    "    overall_sample_weights = []\n",
    "\n",
    "    for stop_seq in df['stop_sequence'].unique():\n",
    "        for day_type in ['weekday', 'weekend']:\n",
    "            df_train_subset = df_train[(df_train['stop_sequence'] == stop_seq) & (df_train['day_of_week'] == day_type)]\n",
    "            df_test_subset = df_test[(df_test['stop_sequence'] == stop_seq) & (df_test['day_of_week'] == day_type)]\n",
    "\n",
    "            drop_columns = ['arrival_delay', 'day_of_week', 'time_of_day', \"weather\", \"temperature\"]\n",
    "            x_train = df_train_subset.drop(columns=drop_columns, errors='ignore').astype('float32')\n",
    "            y_train = df_train_subset['arrival_delay'].astype('float32')\n",
    "            x_test = df_test_subset.drop(columns=drop_columns, errors='ignore').astype('float32')\n",
    "            y_test = df_test_subset['arrival_delay'].astype('float32')\n",
    "\n",
    "            r2_scores_nn = []\n",
    "            r2_scores_lr = []\n",
    "            maes_nn = []\n",
    "            maes_lr = []\n",
    "\n",
    "            # K-fold CV\n",
    "            kf = KFold(n_splits=n_folds)\n",
    "            for train_index, val_index in kf.split(x_train):\n",
    "                x_train_fold, x_val_fold = x_train.iloc[train_index], x_train.iloc[val_index]\n",
    "                y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "                # Train and evaluate NN\n",
    "                model_nn = Sequential([\n",
    "                    Dense(32, activation='relu', input_dim=x_train_fold.shape[1]),\n",
    "                    Dropout(0.001),\n",
    "                    Dense(64, activation='relu'),\n",
    "                    Dense(1)\n",
    "                ])\n",
    "                model_nn.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "                early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "                model_nn.fit(x_train_fold, y_train_fold, validation_data=(x_val_fold, y_val_fold), epochs=100, batch_size=32, callbacks=[early_stopping], verbose=0)\n",
    "                y_pred_nn = model_nn.predict(x_val_fold).flatten()\n",
    "                r2_scores_nn.append(r2_score(y_val_fold, y_pred_nn))\n",
    "                maes_nn.append(mean_absolute_error(y_val_fold, y_pred_nn))\n",
    "\n",
    "                # Train and evaluate LR\n",
    "                model_lr = LinearRegression().fit(x_train_fold, y_train_fold)\n",
    "                y_pred_lr = model_lr.predict(x_val_fold)\n",
    "                r2_scores_lr.append(r2_score(y_val_fold, y_pred_lr))\n",
    "                maes_lr.append(mean_absolute_error(y_val_fold, y_pred_lr))\n",
    "\n",
    "            # Average scores\n",
    "            avg_r2_nn = np.mean(r2_scores_nn)\n",
    "            avg_r2_lr = np.mean(r2_scores_lr)\n",
    "            avg_mae_nn = np.mean(maes_nn)\n",
    "            avg_mae_lr = np.mean(maes_lr)\n",
    "\n",
    "            # Determine best model\n",
    "            if avg_r2_nn > avg_r2_lr:\n",
    "                best_model = \"NN\"\n",
    "                best_r2 = avg_r2_nn\n",
    "                best_mae = avg_mae_nn\n",
    "            else:\n",
    "                best_model = \"LR\"\n",
    "                best_r2 = avg_r2_lr\n",
    "                best_mae = avg_mae_lr\n",
    "\n",
    "            # Save models\n",
    "            model_dir = \"models\"\n",
    "            if not os.path.exists(model_dir):\n",
    "                os.makedirs(model_dir)\n",
    "            if best_model == \"NN\":\n",
    "                model_nn.save(os.path.join(model_dir, f'nn_model_{stop_seq}_{day_type}.h5'))\n",
    "            else:\n",
    "                joblib.dump(model_lr, os.path.join(model_dir, f'lr_model_{stop_seq}_{day_type}.pkl'))\n",
    "\n",
    "            overall_r2_values.append(best_r2)\n",
    "            overall_sample_weights.append(len(df_test_subset))\n",
    "            results['stop_sequence'].append(stop_seq)\n",
    "            results['day_type'].append(day_type)\n",
    "            results['best_model'].append(best_model)\n",
    "            results['R^2'].append(best_r2)\n",
    "            results['MAE'].append(best_mae)\n",
    "\n",
    "    overall_r2 = np.average(overall_r2_values, weights=overall_sample_weights)\n",
    "    print(f\"Overall R^2: {overall_r2:.2f}\")\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# predict_new_data function remains mostly the same.\n",
    "def predict_new_data(df):\n",
    "    all_groups = []  # Placeholder for updated groups\n",
    "\n",
    "    # Group the dataframe by 'stop_sequence' and 'day_of_week'\n",
    "    grouped = df.groupby(['stop_sequence', 'day_of_week'])\n",
    "\n",
    "    for (stop_seq, day_type), group in grouped:\n",
    "        nn_model_path = os.path.join(\"models\", f'nn_model_{stop_seq}_{day_type}.h5')\n",
    "        lr_model_path = os.path.join(\"models\", f'lr_model_{stop_seq}_{day_type}.pkl')\n",
    "\n",
    "        X = group.drop(columns=['arrival_delay', 'day_of_week', 'time_of_day', \"weather\", \"temperature\"], errors='ignore').astype('float32')\n",
    "\n",
    "        if os.path.exists(nn_model_path):\n",
    "            model = load_model(nn_model_path)\n",
    "            group['predicted_delay'] = model.predict(X).flatten()\n",
    "\n",
    "        elif os.path.exists(lr_model_path):\n",
    "            model = joblib.load(lr_model_path)\n",
    "            group['predicted_delay'] = model.predict(X)\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(f\"No saved model found for stop_sequence: {stop_seq} and day_type: {day_type}\")\n",
    "\n",
    "        all_groups.append(group)\n",
    "\n",
    "    # Concatenate all updated groups to get the final dataframe\n",
    "    result_df = pd.concat(all_groups)\n",
    "\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c977579",
   "metadata": {},
   "source": [
    "# Creating the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5602b97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 3ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 1ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 5ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 3ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 3ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 3ms/step\n",
      "78/78 [==============================] - 0s 3ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 3ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 3ms/step\n",
      "78/78 [==============================] - 0s 3ms/step\n",
      "78/78 [==============================] - 0s 3ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "77/77 [==============================] - 0s 3ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 3ms/step\n",
      "77/77 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "78/78 [==============================] - 0s 3ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 3ms/step\n",
      "78/78 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 3ms/step\n",
      "78/78 [==============================] - 0s 3ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 3ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "78/78 [==============================] - 0s 3ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 3ms/step\n",
      "78/78 [==============================] - 0s 3ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 3ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 3ms/step\n",
      "77/77 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 3ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 3ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 3ms/step\n",
      "78/78 [==============================] - 0s 3ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "78/78 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Overall R^2: 0.99\n",
      "    stop_sequence day_type best_model       R^2        MAE\n",
      "0               1  weekday         LR  0.900133  28.803116\n",
      "1               1  weekend         LR  0.957862  26.720768\n",
      "2               2  weekday         LR  0.993873   7.791570\n",
      "3               2  weekend         LR  0.997195   7.002844\n",
      "4               3  weekday         LR  0.994518   7.596034\n",
      "5               3  weekend         LR  0.997320   6.597629\n",
      "6               4  weekday         LR  0.967181  18.583790\n",
      "7               4  weekend         LR  0.991606  11.797418\n",
      "8               5  weekday         LR  0.978429  14.605721\n",
      "9               5  weekend         LR  0.991654  11.572133\n",
      "10              6  weekday         LR  0.986974  13.116409\n",
      "11              6  weekend         LR  0.993378  12.216171\n",
      "12              7  weekday         LR  0.992004  10.127344\n",
      "13              7  weekend         LR  0.996052   9.032592\n",
      "14              8  weekday         LR  0.977516  16.325077\n",
      "15              8  weekend         LR  0.992495  12.827536\n",
      "16              9  weekday         LR  0.994215   8.151249\n",
      "17              9  weekend         LR  0.997515   6.897218\n",
      "18             10  weekday         LR  0.988239  10.277637\n",
      "19             10  weekend         LR  0.996696   8.743966\n",
      "20             11  weekday         LR  0.983303  16.442877\n",
      "21             11  weekend         LR  0.993690  12.496633\n",
      "22             12  weekday         LR  0.990807  12.248227\n",
      "23             12  weekend         LR  0.996075  10.429290\n",
      "24             13  weekday         LR  0.983589  14.896406\n",
      "25             13  weekend         LR  0.990864  13.868892\n",
      "26             14  weekday         LR  0.987366  14.805487\n",
      "27             14  weekend         LR  0.991252  16.118723\n",
      "28             15  weekday         LR  0.995961   6.912200\n",
      "29             15  weekend         LR  0.997819   6.617068\n",
      "30             16  weekday         LR  0.976420  20.401276\n",
      "31             16  weekend         LR  0.992045  14.867783\n",
      "32             17  weekday         LR  0.976795  17.996815\n",
      "33             17  weekend         LR  0.995025  10.809104\n",
      "34             18  weekday         LR  0.975200  21.779547\n",
      "35             18  weekend         LR  0.990083  18.580166\n",
      "36             19  weekday         LR  0.995332   7.955483\n",
      "37             19  weekend         LR  0.998011   6.954459\n",
      "38             20  weekday         LR  0.995124   9.213995\n",
      "39             20  weekend         LR  0.997760   7.894945\n",
      "40             21  weekday         LR  0.992274  13.073642\n",
      "41             21  weekend         LR  0.996298  10.970219\n",
      "42             22  weekday         LR  0.992376  12.000677\n",
      "43             22  weekend         LR  0.997352   8.844440\n",
      "44             23  weekday         LR  0.998353   5.409102\n",
      "45             23  weekend         LR  0.999140   4.732472\n",
      "46             24  weekday         LR  0.995502  10.095038\n",
      "47             24  weekend         LR  0.997354   9.100240\n",
      "48             25  weekday         LR  0.998158   6.588554\n",
      "49             25  weekend         LR  0.999041   5.509778\n",
      "50             26  weekday         LR  0.996249   9.134480\n",
      "51             26  weekend         LR  0.998956   5.529262\n",
      "52             27  weekday         LR  0.982500   9.242070\n",
      "53             27  weekend         LR  0.978773  10.139485\n"
     ]
    }
   ],
   "source": [
    "results_df = train_evaluate_best_model(df)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae68152f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop_seq: 1, day_type: weekday, size: 15480\n",
      "stop_seq: 1, day_type: weekend, size: 4702\n",
      "stop_seq: 2, day_type: weekday, size: 15481\n",
      "stop_seq: 2, day_type: weekend, size: 4702\n",
      "stop_seq: 3, day_type: weekday, size: 15481\n",
      "stop_seq: 3, day_type: weekend, size: 4702\n",
      "stop_seq: 4, day_type: weekday, size: 15480\n",
      "stop_seq: 4, day_type: weekend, size: 4702\n",
      "stop_seq: 5, day_type: weekday, size: 15480\n",
      "stop_seq: 5, day_type: weekend, size: 4702\n",
      "stop_seq: 6, day_type: weekday, size: 15478\n",
      "stop_seq: 6, day_type: weekend, size: 4702\n",
      "stop_seq: 7, day_type: weekday, size: 15480\n",
      "stop_seq: 7, day_type: weekend, size: 4702\n",
      "stop_seq: 8, day_type: weekday, size: 15479\n",
      "stop_seq: 8, day_type: weekend, size: 4702\n",
      "stop_seq: 9, day_type: weekday, size: 15480\n",
      "stop_seq: 9, day_type: weekend, size: 4702\n",
      "stop_seq: 10, day_type: weekday, size: 15480\n",
      "stop_seq: 10, day_type: weekend, size: 4702\n",
      "stop_seq: 11, day_type: weekday, size: 15480\n",
      "stop_seq: 11, day_type: weekend, size: 4702\n",
      "stop_seq: 12, day_type: weekday, size: 15480\n",
      "stop_seq: 12, day_type: weekend, size: 4702\n",
      "stop_seq: 13, day_type: weekday, size: 15480\n",
      "stop_seq: 13, day_type: weekend, size: 4702\n",
      "stop_seq: 14, day_type: weekday, size: 15480\n",
      "stop_seq: 14, day_type: weekend, size: 4702\n",
      "stop_seq: 15, day_type: weekday, size: 15479\n",
      "stop_seq: 15, day_type: weekend, size: 4702\n",
      "stop_seq: 16, day_type: weekday, size: 15480\n",
      "stop_seq: 16, day_type: weekend, size: 4702\n",
      "stop_seq: 17, day_type: weekday, size: 15480\n",
      "stop_seq: 17, day_type: weekend, size: 4702\n",
      "stop_seq: 18, day_type: weekday, size: 15478\n",
      "stop_seq: 18, day_type: weekend, size: 4702\n",
      "stop_seq: 19, day_type: weekday, size: 15473\n",
      "stop_seq: 19, day_type: weekend, size: 4702\n",
      "stop_seq: 20, day_type: weekday, size: 15477\n",
      "stop_seq: 20, day_type: weekend, size: 4702\n",
      "stop_seq: 21, day_type: weekday, size: 15476\n",
      "stop_seq: 21, day_type: weekend, size: 4702\n",
      "stop_seq: 22, day_type: weekday, size: 15477\n",
      "stop_seq: 22, day_type: weekend, size: 4702\n",
      "stop_seq: 23, day_type: weekday, size: 15476\n",
      "stop_seq: 23, day_type: weekend, size: 4702\n",
      "stop_seq: 24, day_type: weekday, size: 15476\n",
      "stop_seq: 24, day_type: weekend, size: 4702\n",
      "stop_seq: 25, day_type: weekday, size: 15476\n",
      "stop_seq: 25, day_type: weekend, size: 4702\n",
      "stop_seq: 26, day_type: weekday, size: 15476\n",
      "stop_seq: 26, day_type: weekend, size: 4702\n",
      "stop_seq: 27, day_type: weekday, size: 15478\n",
      "stop_seq: 27, day_type: weekend, size: 4702\n"
     ]
    }
   ],
   "source": [
    "for stop_seq in df['stop_sequence'].unique():\n",
    "    for day_type in ['weekday', 'weekend']:\n",
    "        subset = df[(df['stop_sequence'] == stop_seq) & (df['day_of_week'] == day_type)]\n",
    "        print(f\"stop_seq: {stop_seq}, day_type: {day_type}, size: {len(subset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e76de2",
   "metadata": {},
   "source": [
    "# USING the trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024c0ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predict_new_data(df)\n",
    "#print(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f197f11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abbbf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the actual and predicted values from the DataFrame\n",
    "actual_values = pred[\"arrival_delay\"].values\n",
    "predicted_values = pred[\"predicGQHW§EÖted_delay\"].values\n",
    "\n",
    "# Computing R^2\n",
    "r2 = r2_score(actual_values, predicted_values)\n",
    "\n",
    "# Computing MAE\n",
    "mae = mean_absolute_error(actual_values, predicted_values)\n",
    "\n",
    "print(f\"R^2: {r2:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fbf56f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
