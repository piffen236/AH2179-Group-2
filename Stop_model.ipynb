{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76714239",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Plot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "import calendar \n",
    "import calplot # actually used\n",
    "\n",
    "# Score model\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Model\n",
    "from sklearn.model_selection import train_test_split, cross_val_score,GridSearchCV\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from scipy import stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1e304c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers removed: 228\n",
      "Size of the original DataFrame: 544875\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read the data\n",
    "url = \"https://raw.githubusercontent.com/zhenliangma/Applied-AI-in-Transportation/main/ProjectAssignmentData/Dataset-PT.csv\"\n",
    "df = pd.read_csv(url, header=1)\n",
    "\n",
    "# Calculate z-scores for the 'arrival_delay' column\n",
    "z_scores = stats.zscore(df['arrival_delay'])\n",
    "\n",
    "# Get boolean array indicating the location of outliers\n",
    "outliers = (z_scores > 7) | (z_scores < -7)\n",
    "\n",
    "# Count the number of outliers\n",
    "num_outliers = outliers.sum()\n",
    "\n",
    "# Print the number of outliers\n",
    "print(f\"Number of outliers removed: {num_outliers}\")\n",
    "\n",
    "# Remove the outliers\n",
    "df = df[~outliers]\n",
    "\n",
    "# Verify the new size of the DataFrame\n",
    "print(f\"Size of the original DataFrame: {len(df)}\")\n",
    "#print(f\"Size of the DataFrame after removing outliers: {len(df_no_outliers)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a884bc",
   "metadata": {},
   "source": [
    "# stop and daytime models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9fdf58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Overall R^2: 0.989619067772344\n",
      "Overall MAE: 12.228547173116066\n",
      "    stop_sequence day_type       R^2        MAE\n",
      "0               1  weekday  0.907789  28.079150\n",
      "1               1  weekend  0.945927  28.133992\n",
      "2               2  weekday  0.994341   7.961897\n",
      "3               2  weekend  0.996451   7.032571\n",
      "4               3  weekday  0.994364   7.562599\n",
      "5               3  weekend  0.997188   6.564969\n",
      "6               4  weekday  0.969525  18.877087\n",
      "7               4  weekend  0.989087  11.836640\n",
      "8               5  weekday  0.979133  14.260601\n",
      "9               5  weekend  0.993399  11.236295\n",
      "10              6  weekday  0.988645  13.048595\n",
      "11              6  weekend  0.993592  12.180406\n",
      "12              7  weekday  0.991089  10.166501\n",
      "13              7  weekend  0.995717   9.197009\n",
      "14              8  weekday  0.979640  16.051619\n",
      "15              8  weekend  0.993770  12.026367\n",
      "16              9  weekday  0.994514   8.123681\n",
      "17              9  weekend  0.997754   6.787489\n",
      "18             10  weekday  0.992584   9.974717\n",
      "19             10  weekend  0.996835   8.387752\n",
      "20             11  weekday  0.985192  16.260256\n",
      "21             11  weekend  0.994672  12.165961\n",
      "22             12  weekday  0.990543  12.154205\n",
      "23             12  weekend  0.995569  10.446174\n",
      "24             13  weekday  0.984427  15.158210\n",
      "25             13  weekend  0.968408  15.139938\n",
      "26             14  weekday  0.985871  15.208541\n",
      "27             14  weekend  0.991506  15.670781\n",
      "28             15  weekday  0.994939   6.915116\n",
      "29             15  weekend  0.998382   6.651905\n",
      "30             16  weekday  0.975115  20.223121\n",
      "31             16  weekend  0.992342  14.921954\n",
      "32             17  weekday  0.978069  18.146161\n",
      "33             17  weekend  0.994967  10.505434\n",
      "34             18  weekday  0.971713  21.915717\n",
      "35             18  weekend  0.988226  18.809726\n",
      "36             19  weekday  0.995652   8.098602\n",
      "37             19  weekend  0.997757   6.920834\n",
      "38             20  weekday  0.994848   9.511890\n",
      "39             20  weekend  0.997438   8.224047\n",
      "40             21  weekday  0.991552  12.958672\n",
      "41             21  weekend  0.996459  11.166504\n",
      "42             22  weekday  0.993169  11.607246\n",
      "43             22  weekend  0.997676   8.472129\n",
      "44             23  weekday  0.998471   5.311370\n",
      "45             23  weekend  0.999146   4.768241\n",
      "46             24  weekday  0.995647  10.122244\n",
      "47             24  weekend  0.997227   9.597449\n",
      "48             25  weekday  0.998093   6.624192\n",
      "49             25  weekend  0.999123   5.451588\n",
      "50             26  weekday  0.996501   8.876780\n",
      "51             26  weekend  0.999041   5.503768\n",
      "52             27  weekday  0.975733  10.094162\n",
      "53             27  weekend  0.976393  10.549976\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "def train_and_evaluate(df):\n",
    "    # Split the entire dataset into training and test sets\n",
    "    df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "    y_mean = df_test['arrival_delay'].mean()\n",
    "\n",
    "    results = {\n",
    "        'stop_sequence': [],\n",
    "        'day_type': [],\n",
    "        'R^2': [],\n",
    "        'MAE': []\n",
    "    }\n",
    "\n",
    "    weighted_mae_sum = 0\n",
    "    total_samples = 0\n",
    "    overall_ssr = 0\n",
    "    overall_tss = 0\n",
    "\n",
    "    for stop_seq in df['stop_sequence'].unique():\n",
    "        for day_type in ['weekday', 'weekend']:\n",
    "            # Filter data by stop sequence and day type\n",
    "            df_train_subset = df_train[(df_train['stop_sequence'] == stop_seq) & (df_train['day_of_week'] == day_type)]\n",
    "            df_test_subset = df_test[(df_test['stop_sequence'] == stop_seq) & (df_test['day_of_week'] == day_type)]\n",
    "\n",
    "            # Train model with RFECV\n",
    "            x_train = df_train_subset.drop(['arrival_delay', 'day_of_week', 'time_of_day', \"weather\", \"temperature\"], axis=1)\n",
    "            y_train = df_train_subset['arrival_delay']\n",
    "\n",
    "            model = LinearRegression()\n",
    "            selector = RFECV(estimator=model, step=1, cv=KFold(5))\n",
    "            selector = selector.fit(x_train, y_train)\n",
    "            \n",
    "            # Fit model with selected features\n",
    "            model.fit(x_train.iloc[:, selector.support_], y_train)\n",
    "\n",
    "            # Evaluate the model\n",
    "            x_test = df_test_subset.drop(['arrival_delay', 'day_of_week', 'time_of_day', \"weather\", \"temperature\"], axis=1).iloc[:, selector.support_]\n",
    "            y_test = df_test_subset['arrival_delay']\n",
    "            \n",
    "            y_pred = model.predict(x_test)\n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "            sample_count = len(y_test)\n",
    "            weighted_mae_sum += mae * sample_count\n",
    "            total_samples += sample_count\n",
    "\n",
    "            residuals = y_test - y_pred\n",
    "            ssr = sum(residuals**2)\n",
    "            overall_ssr += ssr\n",
    "            tss = sum((y_test - y_mean)**2)\n",
    "            overall_tss += tss\n",
    "\n",
    "            results['stop_sequence'].append(stop_seq)\n",
    "            results['day_type'].append(day_type)\n",
    "            results['R^2'].append(r2)\n",
    "            results['MAE'].append(mae)\n",
    "            \n",
    "\n",
    "    overall_r2 = 1 - (overall_ssr / overall_tss)\n",
    "    overall_mae = weighted_mae_sum / total_samples\n",
    "\n",
    "    print(f'Overall R^2: {overall_r2}')\n",
    "    print(f'Overall MAE: {overall_mae}')\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Example usage:\n",
    "results_df = train_and_evaluate(df)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ef02aa",
   "metadata": {},
   "source": [
    "# Only Daytype Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90ab1e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "def train_and_evaluate(df):\n",
    "    # Split the entire dataset into training and test sets\n",
    "    df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "    y_mean = df_test['arrival_delay'].mean()\n",
    "\n",
    "    # Dictionary to store models and selectors\n",
    "    models = {}\n",
    "    selectors = {}\n",
    "    mse_values = {}\n",
    "    mae_values = {}\n",
    "\n",
    "    weighted_mae_sum = 0\n",
    "    total_samples = 0\n",
    "    overall_ssr = 0\n",
    "    overall_tss = 0\n",
    "\n",
    "    # Function to train a model with RFECV\n",
    "    def train_model(df_train_subset):\n",
    "        df_train_subset = df_train_subset.copy()\n",
    "        x_train = df_train_subset.drop(['arrival_delay', 'day_of_week', 'time_of_day', \"weather\", \"temperature\"], axis=1)\n",
    "        y_train = df_train_subset['arrival_delay']\n",
    "\n",
    "        model = LinearRegression()\n",
    "        selector = RFECV(estimator=model, step=1, cv=KFold(5))\n",
    "        selector = selector.fit(x_train, y_train)\n",
    "        \n",
    "        # Fit model with selected features\n",
    "        model.fit(x_train.iloc[:, selector.support_], y_train)\n",
    "        return model, selector\n",
    "\n",
    "    # Function to evaluate a model\n",
    "    def evaluate_model(model, selector, df_test_subset):\n",
    "        nonlocal weighted_mae_sum, total_samples, overall_ssr, overall_tss\n",
    "        \n",
    "        df_test_subset = df_test_subset.copy()\n",
    "        x_test = df_test_subset.drop(['arrival_delay', 'day_of_week', 'time_of_day', \"weather\", \"temperature\"], axis=1).iloc[:, selector.support_]\n",
    "        y_test = df_test_subset['arrival_delay']\n",
    "        \n",
    "        y_pred = model.predict(x_test)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "        sample_count = len(y_test)\n",
    "        weighted_mae_sum += mae * sample_count\n",
    "        total_samples += sample_count\n",
    "\n",
    "        residuals = y_test - y_pred\n",
    "        ssr = sum(residuals**2)\n",
    "        overall_ssr += ssr\n",
    "        tss = sum((y_test - y_mean)**2)\n",
    "        overall_tss += tss\n",
    "\n",
    "        return mse, mae\n",
    "\n",
    "    # Train and evaluate model for weekdays\n",
    "    df_weekday_train = df_train[df_train['day_of_week'] == 'weekday']\n",
    "    models['weekday'], selectors['weekday'] = train_model(df_weekday_train)\n",
    "    mse_values['weekday'], mae_values['weekday'] = evaluate_model(models['weekday'], selectors['weekday'], df_test[df_test['day_of_week'] == 'weekday'])\n",
    "\n",
    "    # Train and evaluate model for weekends\n",
    "    df_weekend_train = df_train[df_train['day_of_week'] == 'weekend']\n",
    "    models['weekend'], selectors['weekend'] = train_model(df_weekend_train)\n",
    "    mse_values['weekend'], mae_values['weekend'] = evaluate_model(models['weekend'], selectors['weekend'], df_test[df_test['day_of_week'] == 'weekend'])\n",
    "\n",
    "    overall_r2 = 1 - (overall_ssr / overall_tss)\n",
    "    overall_mae = weighted_mae_sum / total_samples\n",
    "\n",
    "    print(f'R^2: {overall_r2}')\n",
    "    print(f'MAE: {overall_mae}')\n",
    "\n",
    "    return models, mse_values, mae_values, selectors\n",
    "\n",
    "# Example usage:\n",
    "# trained_models, mse_values, mae_values, selectors = train_and_evaluate(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7650a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.9892383519558062\n",
      "MAE: 12.554114894847544\n",
      "{'weekday': LinearRegression(), 'weekend': LinearRegression()} {'weekday': 403.6346718077232, 'weekend': 343.03050945273117} {'weekday': 13.013826497688935, 'weekend': 11.043052622014638} {'weekday': RFECV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
      "      estimator=LinearRegression()), 'weekend': RFECV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
      "      estimator=LinearRegression())}\n"
     ]
    }
   ],
   "source": [
    "trained_models, mse_values, mae_values, selectors = train_and_evaluate(df)\n",
    "print(trained_models, mse_values, mae_values, selectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b565d6",
   "metadata": {},
   "source": [
    "# Neural network stop and day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f36b8181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "312/312 [==============================] - 3s 5ms/step - loss: 14912.5859 - val_loss: 8766.8887\n",
      "Epoch 2/100\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 3722.0771 - val_loss: 2249.8235\n",
      "Epoch 3/100\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 2163.5276 - val_loss: 2035.9413\n",
      "Epoch 4/100\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 2104.6223 - val_loss: 1970.3821\n",
      "Epoch 5/100\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 2032.9902 - val_loss: 1942.3995\n",
      "Epoch 6/100\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 1995.6667 - val_loss: 1889.1195\n",
      "Epoch 7/100\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 1966.9849 - val_loss: 1864.5614\n",
      "Epoch 8/100\n",
      "310/312 [============================>.] - ETA: 0s - loss: 1943.1512"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vv/61p1g2195ln_91592fly3yk40000gn/T/ipykernel_30860/2709041200.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;31m# Example usage:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m \u001b[0mresults_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_evaluate_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/vv/61p1g2195ln_91592fly3yk40000gn/T/ipykernel_30860/2709041200.py\u001b[0m in \u001b[0;36mtrain_and_evaluate_nn\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mearly_stopping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1830\u001b[0m                             \u001b[0mpss_evaluation_shards\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pss_evaluation_shards\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1831\u001b[0m                         )\n\u001b[0;32m-> 1832\u001b[0;31m                     val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1833\u001b[0m                         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1834\u001b[0m                         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2265\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2266\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2267\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2268\u001b[0m                         with tf.profiler.experimental.Trace(\n\u001b[1;32m   2269\u001b[0m                             \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/src/engine/data_adapter.py\u001b[0m in \u001b[0;36msteps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1409\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1411\u001b[0;31m             \u001b[0moriginal_spe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1412\u001b[0m             can_run_full_execution = (\n\u001b[1;32m   1413\u001b[0m                 \u001b[0moriginal_spe\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    685\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m     raise NotImplementedError(\n\u001b[1;32m    689\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mread_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    812\u001b[0m     \"\"\"\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_variable_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m     \u001b[0;31m# Return an identity so it can get placed on whatever device the context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[0;31m# specifies instead of the device where the variable is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_read_variable_op\u001b[0;34m(self, no_copy)\u001b[0m\n\u001b[1;32m    791\u001b[0m           \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_copy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_copy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mread_and_set_handle\u001b[0;34m(no_copy)\u001b[0m\n\u001b[1;32m    781\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mno_copy\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mforward_compat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_compatible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2022\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0mgen_resource_variable_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable_copy_on_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m       result = gen_resource_variable_ops.read_variable_op(\n\u001b[0m\u001b[1;32m    784\u001b[0m           self.handle, self._dtype)\n\u001b[1;32m    785\u001b[0m       \u001b[0m_maybe_set_handle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py\u001b[0m in \u001b[0;36mread_variable_op\u001b[0;34m(resource, dtype, name)\u001b[0m\n\u001b[1;32m    531\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m    534\u001b[0m         _ctx, \"ReadVariableOp\", name, resource, \"dtype\", dtype)\n\u001b[1;32m    535\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "def train_and_evaluate_nn(df):\n",
    "    # Split the dataset into training and test sets\n",
    "    df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    sc = StandardScaler()\n",
    "\n",
    "    y_mean = df_test['arrival_delay'].mean()\n",
    "    overall_ssr = 0\n",
    "    overall_tss = 0\n",
    "\n",
    "    results = {\n",
    "        'stop_sequence': [],\n",
    "        'day_type': [],\n",
    "        'R^2': [],\n",
    "        'MAE': []\n",
    "    }\n",
    "\n",
    "    for stop_seq in df['stop_sequence'].unique():\n",
    "        for day_type in ['weekday', 'weekend']:\n",
    "            # Filter data\n",
    "            df_train_subset = df_train[(df_train['stop_sequence'] == stop_seq) & (df_train['day_of_week'] == day_type)]\n",
    "            df_test_subset = df_test[(df_test['stop_sequence'] == stop_seq) & (df_test['day_of_week'] == day_type)]\n",
    "\n",
    "            # Prepare data\n",
    "            x_train = df_train_subset.drop(['arrival_delay', 'day_of_week', 'time_of_day', \"weather\", \"temperature\"], axis=1)\n",
    "            y_train = df_train_subset['arrival_delay']\n",
    "            \n",
    "            x_test = df_test_subset.drop(['arrival_delay', 'day_of_week', 'time_of_day', \"weather\", \"temperature\"], axis=1)\n",
    "            y_test = df_test_subset['arrival_delay']\n",
    "\n",
    "            # Normalize the input features\n",
    "            x_train = sc.fit_transform(x_train)\n",
    "            x_test = sc.transform(x_test)\n",
    "\n",
    "            # Neural network model\n",
    "            model = Sequential()\n",
    "            model.add(Dense(32, activation='relu', input_dim=x_train.shape[1]))\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(Dense(16, activation='relu'))\n",
    "            model.add(Dense(1))\n",
    "\n",
    "            model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "\n",
    "            early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "            model.fit(x_train, y_train, validation_split=0.2, epochs=100, batch_size=32, callbacks=[early_stopping], verbose=1)\n",
    "            \n",
    "            y_pred = model.predict(x_test).flatten()\n",
    "            current_r2 = r2_score(y_test, y_pred)\n",
    "            current_mae = mean_absolute_error(y_test, y_pred)\n",
    "            \n",
    "            residuals = y_test - y_pred\n",
    "            ssr = sum(residuals**2)\n",
    "            overall_ssr += ssr\n",
    "            tss = sum((y_test - y_mean)**2)\n",
    "            overall_tss += tss\n",
    "\n",
    "            results['stop_sequence'].append(stop_seq)\n",
    "            results['day_type'].append(day_type)\n",
    "            results['R^2'].append(current_r2)\n",
    "            results['MAE'].append(current_mae)\n",
    "\n",
    "    overall_r2 = 1 - (overall_ssr / overall_tss)\n",
    "    print(f'Overall R^2 for Neural Network: {overall_r2}')\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Example usage:\n",
    "results_df = train_and_evaluate_nn(df)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f8607e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_models, mse_values, mae_values = train_and_evaluate(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3ca573",
   "metadata": {},
   "source": [
    "# NN VS LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7313bb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is already loaded and available\n",
    "unique_stops = df['stop_sequence'].unique()\n",
    "selected_stops = unique_stops[:4]\n",
    "\n",
    "df_test = df[df['stop_sequence'].isin(selected_stops)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2d9c4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_best_model(df):\n",
    "\n",
    "    # Split the dataset into training and test sets\n",
    "    df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    sc = StandardScaler()\n",
    "    \n",
    "    # Create a placeholder for results\n",
    "    results = {\n",
    "        'stop_sequence': [],\n",
    "        'day_type': [],\n",
    "        'best_model': [],\n",
    "        'R^2': [],\n",
    "        'MAE': []\n",
    "    }\n",
    "\n",
    "    for stop_seq in df['stop_sequence'].unique():\n",
    "        for day_type in ['weekday', 'weekend']:\n",
    "            # Filter data\n",
    "            df_train_subset = df_train[(df_train['stop_sequence'] == stop_seq) & (df_train['day_of_week'] == day_type)]\n",
    "            df_test_subset = df_test[(df_test['stop_sequence'] == stop_seq) & (df_test['day_of_week'] == day_type)]\n",
    "            \n",
    "            # Common data preparation\n",
    "            x_train = df_train_subset.drop(['arrival_delay', 'day_of_week', 'time_of_day', \"weather\", \"temperature\"], axis=1)\n",
    "            y_train = df_train_subset['arrival_delay']\n",
    "            x_test = df_test_subset.drop(['arrival_delay', 'day_of_week', 'time_of_day', \"weather\", \"temperature\"], axis=1)\n",
    "            y_test = df_test_subset['arrival_delay']\n",
    "\n",
    "            # Normalize the input features for NN\n",
    "            x_train_nn = sc.fit_transform(x_train)\n",
    "            x_test_nn = sc.transform(x_test)\n",
    "\n",
    "            # Train and evaluate NN\n",
    "            model_nn = Sequential()\n",
    "            model_nn.add(Dense(32, activation='relu', input_dim=x_train_nn.shape[1]))\n",
    "            model_nn.add(Dropout(0.2))\n",
    "            model_nn.add(Dense(16, activation='relu'))\n",
    "            model_nn.add(Dense(1))\n",
    "            model_nn.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "            early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "            model_nn.fit(x_train_nn, y_train, validation_split=0.2, epochs=100, batch_size=32, callbacks=[early_stopping], verbose=0)\n",
    "            y_pred_nn = model_nn.predict(x_test_nn).flatten()\n",
    "            r2_nn = r2_score(y_test, y_pred_nn)\n",
    "            mae_nn = mean_absolute_error(y_test, y_pred_nn)\n",
    "\n",
    "            # Train and evaluate Linear Regression\n",
    "            model_lr = LinearRegression()\n",
    "            selector = RFECV(estimator=model_lr, step=1, cv=KFold(5))\n",
    "            selector = selector.fit(x_train, y_train)\n",
    "            model_lr.fit(x_train.iloc[:, selector.support_], y_train)\n",
    "            y_pred_lr = model_lr.predict(x_test.iloc[:, selector.support_])\n",
    "            r2_lr = r2_score(y_test, y_pred_lr)\n",
    "            mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
    "\n",
    "            # Compare and store results\n",
    "            if r2_nn > r2_lr:\n",
    "                best_model = \"NN\"\n",
    "                best_r2 = r2_nn\n",
    "                best_mae = mae_nn\n",
    "            else:\n",
    "                best_model = \"LR\"\n",
    "                best_r2 = r2_lr\n",
    "                best_mae = mae_lr\n",
    "\n",
    "            results['stop_sequence'].append(stop_seq)\n",
    "            results['day_type'].append(day_type)\n",
    "            results['best_model'].append(best_model)\n",
    "            results['R^2'].append(best_r2)\n",
    "            results['MAE'].append(best_mae)\n",
    "            print(\"Done\")\n",
    "            \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0567acf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/97 [==============================] - 0s 2ms/step\n",
      "Done\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "Done\n",
      "100/100 [==============================] - 0s 4ms/step\n",
      "Done\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "results_df = train_evaluate_best_model(df_test)\n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
