{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "76714239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Plot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "import calendar \n",
    "import calplot # actually used\n",
    "\n",
    "# Score model\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Model\n",
    "from sklearn.model_selection import train_test_split, cross_val_score,GridSearchCV\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from scipy import stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a01703",
   "metadata": {},
   "source": [
    "# Dataframe setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d1e304c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers removed: 228\n",
      "Size of the original DataFrame: 544875\n"
     ]
    }
   ],
   "source": [
    "# Read the data\n",
    "url = \"https://raw.githubusercontent.com/zhenliangma/Applied-AI-in-Transportation/main/ProjectAssignmentData/Dataset-PT.csv\"\n",
    "df = pd.read_csv(url, header=1)\n",
    "#df = df.drop(columns=['weather', 'temperature', 'day_of_week', 'time_of_day'])\n",
    "# Calculate z-scores for the 'arrival_delay' column\n",
    "z_scores = stats.zscore(df['arrival_delay'])\n",
    "\n",
    "# Get boolean array indicating the location of outliers\n",
    "outliers = (z_scores > 7) | (z_scores < -7)\n",
    "\n",
    "# Count the number of outliers\n",
    "num_outliers = outliers.sum()\n",
    "\n",
    "# Print the number of outliers\n",
    "print(f\"Number of outliers removed: {num_outliers}\")\n",
    "\n",
    "# Remove the outliers\n",
    "df = df[~outliers]\n",
    "\n",
    "# Verify the new size of the DataFrame\n",
    "print(f\"Size of the original DataFrame: {len(df)}\")\n",
    "#print(f\"Size of the DataFrame after removing outliers: {len(df_no_outliers)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a884bc",
   "metadata": {},
   "source": [
    "# stop and daytime model (LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e9fdf58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "def train_evaluate_lr_model(df, n_folds=5):\n",
    "    df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "    results = {\n",
    "        'stop_sequence': [],\n",
    "        'day_type': [],\n",
    "        'R^2': [],\n",
    "        'MAE': []\n",
    "    }\n",
    "\n",
    "    for stop_seq in df['stop_sequence'].unique():\n",
    "        for day_type in ['weekday', 'weekend']:\n",
    "            print(f\"Processing stop_sequence {stop_seq} for {day_type}...\")\n",
    "            \n",
    "            df_train_subset = df_train[(df_train['stop_sequence'] == stop_seq) & (df_train['day_of_week'] == day_type)]\n",
    "\n",
    "            drop_columns = ['arrival_delay', 'day_of_week', 'time_of_day', \"weather\", \"temperature\"]\n",
    "            x_train = df_train_subset.drop(columns=drop_columns, errors='ignore').astype('float32')\n",
    "            y_train = df_train_subset['arrival_delay'].astype('float32')\n",
    "\n",
    "            r2_scores_lr = []\n",
    "            maes_lr = []\n",
    "\n",
    "            # K-fold CV\n",
    "            kf = KFold(n_splits=n_folds)\n",
    "            for fold, (train_index, val_index) in enumerate(kf.split(x_train)):\n",
    "                print(f\"Running Fold {fold + 1}...\")\n",
    "\n",
    "                x_train_fold, x_val_fold = x_train.iloc[train_index], x_train.iloc[val_index]\n",
    "                y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "                # Train and evaluate LR\n",
    "                print(\"Training Linear Regression...\")\n",
    "                model_lr = LinearRegression().fit(x_train_fold, y_train_fold)\n",
    "                y_pred_lr = model_lr.predict(x_val_fold)\n",
    "                r2_scores_lr.append(r2_score(y_val_fold, y_pred_lr))\n",
    "                maes_lr.append(mean_absolute_error(y_val_fold, y_pred_lr))\n",
    "\n",
    "            # Save LR model\n",
    "            best_r2 = np.mean(r2_scores_lr)\n",
    "            best_mae = np.mean(maes_lr)\n",
    "            if not os.path.exists(\"lr_models\"):\n",
    "                os.makedirs(\"lr_models\")\n",
    "            joblib.dump(model_lr, os.path.join(\"lr_models\", f'lr_model_{stop_seq}_{day_type}.pkl'))\n",
    "\n",
    "            results['stop_sequence'].append(stop_seq)\n",
    "            results['day_type'].append(day_type)\n",
    "            results['R^2'].append(best_r2)\n",
    "            results['MAE'].append(best_mae)\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def predict_with_lr_model(df):\n",
    "    all_groups = []\n",
    "\n",
    "    grouped = df.groupby(['stop_sequence', 'day_of_week'])\n",
    "    for (stop_seq, day_type), group in grouped:\n",
    "        lr_model_path = os.path.join(\"lr_models\", f'lr_model_{stop_seq}_{day_type}.pkl')\n",
    "\n",
    "        X = group.drop(columns=['arrival_delay', 'day_of_week', 'time_of_day', \"weather\", \"temperature\"], errors='ignore').astype('float32')\n",
    "        \n",
    "        if os.path.exists(lr_model_path):\n",
    "            model = joblib.load(lr_model_path)\n",
    "            group['predicted_delay'] = model.predict(X)\n",
    "        else:\n",
    "            raise ValueError(f\"No saved model found for stop_sequence: {stop_seq} and day_type: {day_type}\")\n",
    "\n",
    "        all_groups.append(group)\n",
    "\n",
    "    result_df = pd.concat(all_groups)\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d4ff8dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing stop_sequence 1 for weekday...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 1 for weekend...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 2 for weekday...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 2 for weekend...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 3 for weekday...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 3 for weekend...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 4 for weekday...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 4 for weekend...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 5 for weekday...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 5 for weekend...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 6 for weekday...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 6 for weekend...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 7 for weekday...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 7 for weekend...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 8 for weekday...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 8 for weekend...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 9 for weekday...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 9 for weekend...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 10 for weekday...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 10 for weekend...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 11 for weekday...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 11 for weekend...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 12 for weekday...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 12 for weekend...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 13 for weekday...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 13 for weekend...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 14 for weekday...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 14 for weekend...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 15 for weekday...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 15 for weekend...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 16 for weekday...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 16 for weekend...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 17 for weekday...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 17 for weekend...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 18 for weekday...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 18 for weekend...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 19 for weekday...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 19 for weekend...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 20 for weekday...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 20 for weekend...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 21 for weekday...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 21 for weekend...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 22 for weekday...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 22 for weekend...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 23 for weekday...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 23 for weekend...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 24 for weekday...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 24 for weekend...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 25 for weekday...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 25 for weekend...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 26 for weekday...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 26 for weekend...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 27 for weekday...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "Processing stop_sequence 27 for weekend...\n",
      "Running Fold 1...\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Linear Regression...\n",
      "    stop_sequence day_type       R^2        MAE\n",
      "0               1  weekday  0.900133  28.803116\n",
      "1               1  weekend  0.957862  26.720768\n",
      "2               2  weekday  0.993873   7.791570\n",
      "3               2  weekend  0.997195   7.002844\n",
      "4               3  weekday  0.994518   7.596034\n",
      "5               3  weekend  0.997320   6.597629\n",
      "6               4  weekday  0.967181  18.583790\n",
      "7               4  weekend  0.991606  11.797418\n",
      "8               5  weekday  0.978429  14.605721\n",
      "9               5  weekend  0.991654  11.572133\n",
      "10              6  weekday  0.986974  13.116409\n",
      "11              6  weekend  0.993378  12.216171\n",
      "12              7  weekday  0.992004  10.127344\n",
      "13              7  weekend  0.996052   9.032592\n",
      "14              8  weekday  0.977516  16.325077\n",
      "15              8  weekend  0.992495  12.827536\n",
      "16              9  weekday  0.994215   8.151249\n",
      "17              9  weekend  0.997515   6.897218\n",
      "18             10  weekday  0.988239  10.277637\n",
      "19             10  weekend  0.996696   8.743966\n",
      "20             11  weekday  0.983303  16.442877\n",
      "21             11  weekend  0.993690  12.496633\n",
      "22             12  weekday  0.990807  12.248227\n",
      "23             12  weekend  0.996075  10.429290\n",
      "24             13  weekday  0.983589  14.896406\n",
      "25             13  weekend  0.990864  13.868892\n",
      "26             14  weekday  0.987366  14.805487\n",
      "27             14  weekend  0.991252  16.118723\n",
      "28             15  weekday  0.995961   6.912200\n",
      "29             15  weekend  0.997819   6.617068\n",
      "30             16  weekday  0.976420  20.401276\n",
      "31             16  weekend  0.992045  14.867783\n",
      "32             17  weekday  0.976795  17.996815\n",
      "33             17  weekend  0.995025  10.809104\n",
      "34             18  weekday  0.975200  21.779547\n",
      "35             18  weekend  0.990083  18.580166\n",
      "36             19  weekday  0.995332   7.955483\n",
      "37             19  weekend  0.998011   6.954459\n",
      "38             20  weekday  0.995124   9.213995\n",
      "39             20  weekend  0.997760   7.894945\n",
      "40             21  weekday  0.992274  13.073642\n",
      "41             21  weekend  0.996298  10.970219\n",
      "42             22  weekday  0.992376  12.000677\n",
      "43             22  weekend  0.997352   8.844440\n",
      "44             23  weekday  0.998353   5.409102\n",
      "45             23  weekend  0.999140   4.732472\n",
      "46             24  weekday  0.995502  10.095038\n",
      "47             24  weekend  0.997354   9.100240\n",
      "48             25  weekday  0.998158   6.588554\n",
      "49             25  weekend  0.999041   5.509778\n",
      "50             26  weekday  0.996249   9.134480\n",
      "51             26  weekend  0.998956   5.529262\n",
      "52             27  weekday  0.982500   9.242070\n",
      "53             27  weekend  0.978773  10.139485\n"
     ]
    }
   ],
   "source": [
    "results_lr = train_evaluate_lr_model(df)\n",
    "print(results_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5aad2915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.990044\n",
      "MAE: 12.214730\n"
     ]
    }
   ],
   "source": [
    "pred = predict_with_lr_model(df)\n",
    "pred.head()\n",
    "# Extracting the actual and predicted values from the DataFrame\n",
    "actual_values = pred[\"arrival_delay\"].values\n",
    "predicted_values = pred[\"predicted_delay\"].values\n",
    "\n",
    "# Computing R^2\n",
    "r2 = r2_score(actual_values, predicted_values)\n",
    "\n",
    "# Computing MAE\n",
    "mae = mean_absolute_error(actual_values, predicted_values)\n",
    "\n",
    "print(f\"R^2: {r2:f}\")\n",
    "print(f\"MAE: {mae:f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c08729",
   "metadata": {},
   "source": [
    "# Only Daytype Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90ab1e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pandas as pd\n",
    "\n",
    "def train_and_evaluate(df):\n",
    "    # Split the dataset\n",
    "    df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Results placeholder\n",
    "    results = {\n",
    "        'day_type': [],\n",
    "        'best_model': [],\n",
    "        'MSE': [],\n",
    "        'MAE': [],\n",
    "        'R^2': []  \n",
    "    }\n",
    "\n",
    "    # Function to train and evaluate Linear Regression with RFECV\n",
    "    def train_lr_model(df_train_subset):\n",
    "        x_train = df_train_subset.drop(['arrival_delay', 'day_of_week', 'time_of_day', \"weather\", \"temperature\"], axis=1)\n",
    "        y_train = df_train_subset['arrival_delay']\n",
    "\n",
    "        model = LinearRegression()\n",
    "        selector = RFECV(estimator=model, step=1, cv=KFold(5))\n",
    "        selector = selector.fit(x_train, y_train)\n",
    "\n",
    "        model.fit(x_train.iloc[:, selector.support_], y_train)\n",
    "        \n",
    "        return model, selector\n",
    "\n",
    "    # Function to train Neural Network\n",
    "    def train_nn_model(df_train_subset):\n",
    "        x_train = df_train_subset.drop(['arrival_delay', 'day_of_week', 'time_of_day', \"weather\", \"temperature\"], axis=1)\n",
    "        y_train = df_train_subset['arrival_delay']\n",
    "\n",
    "        model_nn = Sequential([\n",
    "            Dense(32, activation='relu', input_dim=x_train.shape[1]),\n",
    "            Dropout(0.001),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dense(1)\n",
    "        ])\n",
    "        model_nn.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "        model_nn.fit(x_train, y_train, validation_split=0.2, epochs=100, batch_size=32, callbacks=[early_stopping], verbose=0)\n",
    "        \n",
    "        return model_nn\n",
    "\n",
    "    for day_type in ['weekday', 'weekend']:\n",
    "        df_train_subset = df_train[df_train['day_of_week'] == day_type]\n",
    "        df_test_subset = df_test[df_test['day_of_week'] == day_type]\n",
    "\n",
    "        # Train and evaluate Linear Regression model\n",
    "        model_lr, selector = train_lr_model(df_train_subset)\n",
    "        x_test = df_test_subset.drop(['arrival_delay', 'day_of_week', 'time_of_day', \"weather\", \"temperature\"], axis=1).iloc[:, selector.support_]\n",
    "        y_pred_lr = model_lr.predict(x_test)\n",
    "        mse_lr = mean_squared_error(df_test_subset['arrival_delay'], y_pred_lr)\n",
    "        mae_lr = mean_absolute_error(df_test_subset['arrival_delay'], y_pred_lr)\n",
    "        r2_lr = r2_score(df_test_subset['arrival_delay'], y_pred_lr)\n",
    "        # Train and evaluate Neural Network\n",
    "        model_nn = train_nn_model(df_train_subset)\n",
    "        y_pred_nn = model_nn.predict(df_test_subset.drop(['arrival_delay', 'day_of_week', 'time_of_day', \"weather\", \"temperature\"], axis=1)).flatten()\n",
    "        mse_nn = mean_squared_error(df_test_subset['arrival_delay'], y_pred_nn)\n",
    "        mae_nn = mean_absolute_error(df_test_subset['arrival_delay'], y_pred_nn)\n",
    "        r2_nn = r2_score(df_test_subset['arrival_delay'], y_pred_nn)\n",
    "\n",
    "        # Choose the best model based on MAE\n",
    "        if mae_nn < mae_lr:\n",
    "            best_model = \"NN\"\n",
    "            best_mse = mse_nn\n",
    "            best_mae = mae_nn\n",
    "            best_r2 = r2_nn\n",
    "        else:\n",
    "            best_model = \"LR\"\n",
    "            best_mse = mse_lr\n",
    "            best_mae = mae_lr\n",
    "            best_r2 = r2_lr\n",
    "\n",
    "        results['day_type'].append(day_type)\n",
    "        results['best_model'].append(best_model)\n",
    "        results['MSE'].append(best_mse)\n",
    "        results['MAE'].append(best_mae)\n",
    "        results['R^2'].append(best_r2)\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Example usage:\n",
    "# df = ...  # Your dataframe\n",
    "# result_df = train_and_evaluate(df)\n",
    "# print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7650a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2612/2612 [==============================] - 5s 2ms/step\n",
      "795/795 [==============================] - 2s 3ms/step\n",
      "  day_type best_model         MSE        MAE       R^2\n",
      "0  weekday         LR  403.634672  13.013826  0.986993\n",
      "1  weekend         LR  343.030509  11.043053  0.992785\n"
     ]
    }
   ],
   "source": [
    "results = train_and_evaluate(df)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eed627e",
   "metadata": {},
   "source": [
    "# NN VS LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b245a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "09fab492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "def train_evaluate_best_model(df, n_folds=5):\n",
    "    df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "    results = {\n",
    "        'stop_sequence': [],\n",
    "        'day_type': [],\n",
    "        'best_model': [],\n",
    "        'R^2': [],\n",
    "        'MAE': []\n",
    "    }\n",
    "\n",
    "    for stop_seq in df['stop_sequence'].unique():\n",
    "        for day_type in ['weekday', 'weekend']:\n",
    "            print(f\"Processing stop_sequence {stop_seq} for {day_type}...\")\n",
    "            \n",
    "            df_train_subset = df_train[(df_train['stop_sequence'] == stop_seq) & (df_train['day_of_week'] == day_type)]\n",
    "            df_test_subset = df_test[(df_test['stop_sequence'] == stop_seq) & (df_test['day_of_week'] == day_type)]\n",
    "\n",
    "            drop_columns = ['arrival_delay', 'day_of_week', 'time_of_day', \"weather\", \"temperature\"]\n",
    "            x_train = df_train_subset.drop(columns=drop_columns, errors='ignore').astype('float32')\n",
    "            y_train = df_train_subset['arrival_delay'].astype('float32')\n",
    "\n",
    "            # Normalize the data for NN\n",
    "            scaler = StandardScaler()\n",
    "            x_train_normalized = scaler.fit_transform(x_train)\n",
    "            \n",
    "            # Save the scaler\n",
    "            if not os.path.exists(\"scalers\"):\n",
    "                os.makedirs(\"scalers\")\n",
    "            joblib.dump(scaler, os.path.join(\"scalers\", f'scaler_{stop_seq}_{day_type}.pkl'))\n",
    "\n",
    "            r2_scores_nn = []\n",
    "            r2_scores_lr = []\n",
    "            maes_nn = []\n",
    "            maes_lr = []\n",
    "\n",
    "            # K-fold CV\n",
    "            kf = KFold(n_splits=n_folds)\n",
    "            for fold, (train_index, val_index) in enumerate(kf.split(x_train_normalized)):\n",
    "                print(f\"Running Fold {fold + 1}...\")\n",
    "\n",
    "                x_train_fold, x_val_fold = x_train_normalized[train_index], x_train_normalized[val_index]\n",
    "                y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "                # Train and evaluate NN\n",
    "                print(\"Training Neural Network...\")\n",
    "                model_nn = Sequential([\n",
    "                    Dense(64, activation='relu', input_dim=x_train_fold.shape[1]),\n",
    "                    Dense(32, activation='relu'),\n",
    "                    Dense(16, activation='relu'),\n",
    "                    Dense(1)\n",
    "                ])\n",
    "                model_nn.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "                early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "                model_nn.fit(x_train_fold, y_train_fold, validation_data=(x_val_fold, y_val_fold), epochs=100, batch_size=16, callbacks=[early_stopping], verbose=0)\n",
    "                y_pred_nn = model_nn.predict(x_val_fold).flatten()\n",
    "                r2_scores_nn.append(r2_score(y_val_fold, y_pred_nn))\n",
    "                maes_nn.append(mean_absolute_error(y_val_fold, y_pred_nn))\n",
    "\n",
    "                # Train and evaluate LR\n",
    "                print(\"Training Linear Regression...\")\n",
    "                model_lr = LinearRegression().fit(x_train_fold, y_train_fold)\n",
    "                y_pred_lr = model_lr.predict(x_val_fold)\n",
    "                r2_scores_lr.append(r2_score(y_val_fold, y_pred_lr))\n",
    "                maes_lr.append(mean_absolute_error(y_val_fold, y_pred_lr))\n",
    "\n",
    "            # Determine best model and save it\n",
    "            avg_mae_nn = np.mean(maes_nn)\n",
    "            avg_mae_lr = np.mean(maes_lr)\n",
    "            print(\"LR:\",avg_mae_lr)\n",
    "            print(\"NN:\",avg_mae_nn)\n",
    "            if avg_mae_nn < avg_mae_lr:\n",
    "                best_model = \"NN\"\n",
    "                best_r2 = np.mean(r2_scores_nn)\n",
    "                best_mae = avg_mae_nn\n",
    "                # Save NN model\n",
    "                if not os.path.exists(\"models\"):\n",
    "                    os.makedirs(\"models\")\n",
    "                model_nn.save(os.path.join(\"models\", f'nn_model_{stop_seq}_{day_type}.h5'))\n",
    "            else:\n",
    "                best_model = \"LR\"\n",
    "                best_r2 = np.mean(r2_scores_lr)\n",
    "                best_mae = avg_mae_lr\n",
    "                # Save LR model\n",
    "                if not os.path.exists(\"models\"):\n",
    "                    os.makedirs(\"models\")\n",
    "                joblib.dump(model_lr, os.path.join(\"models\", f'lr_model_{stop_seq}_{day_type}.pkl'))\n",
    "\n",
    "            results['stop_sequence'].append(stop_seq)\n",
    "            results['day_type'].append(day_type)\n",
    "            results['best_model'].append(best_model)\n",
    "            results['R^2'].append(best_r2)\n",
    "            results['MAE'].append(best_mae)\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def predict_new_data(df):\n",
    "    all_groups = []\n",
    "\n",
    "    grouped = df.groupby(['stop_sequence', 'day_of_week'])\n",
    "    for (stop_seq, day_type), group in grouped:\n",
    "        nn_model_path = os.path.join(\"models\", f'nn_model_{stop_seq}_{day_type}.h5')\n",
    "        lr_model_path = os.path.join(\"models\", f'lr_model_{stop_seq}_{day_type}.pkl')\n",
    "        scaler_path = os.path.join(\"scalers\", f'scaler_{stop_seq}_{day_type}.pkl')  # Load the scaler\n",
    "        \n",
    "        X = group.drop(columns=['arrival_delay', 'day_of_week', 'time_of_day', \"weather\", \"temperature\"], errors='ignore').astype('float32')\n",
    "\n",
    "        # Normalize the data with the saved scaler\n",
    "        scaler = joblib.load(scaler_path)\n",
    "        X_normalized = scaler.transform(X)\n",
    "\n",
    "        if os.path.exists(nn_model_path):\n",
    "            model = load_model(nn_model_path)\n",
    "            group['predicted_delay'] = model.predict(X_normalized).flatten()\n",
    "        elif os.path.exists(lr_model_path):\n",
    "            model = joblib.load(lr_model_path)\n",
    "            group['predicted_delay'] = model.predict(X)\n",
    "        else:\n",
    "            raise ValueError(f\"No saved model found for stop_sequence: {stop_seq} and day_type: {day_type}\")\n",
    "\n",
    "        all_groups.append(group)\n",
    "\n",
    "    result_df = pd.concat(all_groups)\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c977579",
   "metadata": {},
   "source": [
    "### Creating the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5602b97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing stop_sequence 1 for weekday...\n",
      "Running Fold 1...\n",
      "Training Neural Network...\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Neural Network...\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Neural Network...\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Neural Network...\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Neural Network...\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "Training Linear Regression...\n",
      "LR: 28.80708\n",
      "NN: 28.301798\n",
      "Processing stop_sequence 1 for weekend...\n",
      "Running Fold 1...\n",
      "Training Neural Network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 2ms/step\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Neural Network...\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Neural Network...\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Neural Network...\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Neural Network...\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Training Linear Regression...\n",
      "LR: 26.756924\n",
      "NN: 27.07781\n",
      "Processing stop_sequence 2 for weekday...\n",
      "Running Fold 1...\n",
      "Training Neural Network...\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Neural Network...\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Neural Network...\n",
      "78/78 [==============================] - 0s 3ms/step\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Neural Network...\n",
      "78/78 [==============================] - 0s 3ms/step\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Neural Network...\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "Training Linear Regression...\n",
      "LR: 7.7936544\n",
      "NN: 8.108984\n",
      "Processing stop_sequence 2 for weekend...\n",
      "Running Fold 1...\n",
      "Training Neural Network...\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Neural Network...\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Neural Network...\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Neural Network...\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Neural Network...\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Training Linear Regression...\n",
      "LR: 6.9967012\n",
      "NN: 7.9694633\n",
      "Processing stop_sequence 3 for weekday...\n",
      "Running Fold 1...\n",
      "Training Neural Network...\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Neural Network...\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Neural Network...\n",
      "77/77 [==============================] - 0s 3ms/step\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Neural Network...\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Neural Network...\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "Training Linear Regression...\n",
      "LR: 7.598422\n",
      "NN: 7.8599677\n",
      "Processing stop_sequence 3 for weekend...\n",
      "Running Fold 1...\n",
      "Training Neural Network...\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Neural Network...\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Neural Network...\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Neural Network...\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Neural Network...\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "Training Linear Regression...\n",
      "LR: 6.597661\n",
      "NN: 7.651119\n",
      "Processing stop_sequence 4 for weekday...\n",
      "Running Fold 1...\n",
      "Training Neural Network...\n",
      "78/78 [==============================] - 0s 3ms/step\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Neural Network...\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Neural Network...\n",
      "78/78 [==============================] - 0s 3ms/step\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Neural Network...\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Neural Network...\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "Training Linear Regression...\n",
      "LR: 18.588211\n",
      "NN: 18.914955\n",
      "Processing stop_sequence 4 for weekend...\n",
      "Running Fold 1...\n",
      "Training Neural Network...\n",
      "24/24 [==============================] - 0s 1ms/step\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Neural Network...\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Neural Network...\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Neural Network...\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Neural Network...\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Training Linear Regression...\n",
      "LR: 11.797165\n",
      "NN: 12.509182\n",
      "Processing stop_sequence 5 for weekday...\n",
      "Running Fold 1...\n",
      "Training Neural Network...\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Neural Network...\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Neural Network...\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Neural Network...\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Neural Network...\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "Training Linear Regression...\n",
      "LR: 14.609756\n",
      "NN: 14.775577\n",
      "Processing stop_sequence 5 for weekend...\n",
      "Running Fold 1...\n",
      "Training Neural Network...\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Training Linear Regression...\n",
      "Running Fold 2...\n",
      "Training Neural Network...\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Training Linear Regression...\n",
      "Running Fold 3...\n",
      "Training Neural Network...\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Training Linear Regression...\n",
      "Running Fold 4...\n",
      "Training Neural Network...\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Training Linear Regression...\n",
      "Running Fold 5...\n",
      "Training Neural Network...\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Training Linear Regression...\n",
      "LR: 11.566103\n",
      "NN: 12.386055\n",
      "Processing stop_sequence 6 for weekday...\n",
      "Running Fold 1...\n",
      "Training Neural Network...\n"
     ]
    }
   ],
   "source": [
    "results_df = train_evaluate_best_model(df)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e76de2",
   "metadata": {},
   "source": [
    "### USING the trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "024c0ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484/484 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484/484 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484/484 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484/484 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484/484 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/jesperhelen/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pred = predict_new_data(df)\n",
    "#print(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f197f11a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Calendar_date</th>\n",
       "      <th>route_id</th>\n",
       "      <th>bus_id</th>\n",
       "      <th>stop_sequence</th>\n",
       "      <th>arrival_delay</th>\n",
       "      <th>dwell_time</th>\n",
       "      <th>travel_time_for_previous_section</th>\n",
       "      <th>scheduled_travel_time</th>\n",
       "      <th>upstream_stop_delay</th>\n",
       "      <th>origin_delay</th>\n",
       "      <th>...</th>\n",
       "      <th>factor(weather)Snow</th>\n",
       "      <th>factor(temperature)Cold</th>\n",
       "      <th>factor(temperature)Extra_cold</th>\n",
       "      <th>factor(temperature)Normal</th>\n",
       "      <th>factor(day_of_week)weekday</th>\n",
       "      <th>factor(day_of_week)weekend</th>\n",
       "      <th>factor(time_of_day)Afternoon_peak</th>\n",
       "      <th>factor(time_of_day)Morning_peak</th>\n",
       "      <th>factor(time_of_day)Off-peak</th>\n",
       "      <th>predicted_delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3186</th>\n",
       "      <td>20220110</td>\n",
       "      <td>4</td>\n",
       "      <td>44410</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.267187e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3213</th>\n",
       "      <td>20220110</td>\n",
       "      <td>4</td>\n",
       "      <td>41370</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.267306e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3240</th>\n",
       "      <td>20220110</td>\n",
       "      <td>4</td>\n",
       "      <td>41353</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.267272e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3267</th>\n",
       "      <td>20220110</td>\n",
       "      <td>4</td>\n",
       "      <td>44413</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.267221e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3294</th>\n",
       "      <td>20220110</td>\n",
       "      <td>4</td>\n",
       "      <td>45544</td>\n",
       "      <td>1</td>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.267323e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342469</th>\n",
       "      <td>20220420</td>\n",
       "      <td>4</td>\n",
       "      <td>44059</td>\n",
       "      <td>2</td>\n",
       "      <td>109</td>\n",
       "      <td>83</td>\n",
       "      <td>153</td>\n",
       "      <td>90</td>\n",
       "      <td>60</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.911516e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342496</th>\n",
       "      <td>20220420</td>\n",
       "      <td>4</td>\n",
       "      <td>44066</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>119</td>\n",
       "      <td>101</td>\n",
       "      <td>90</td>\n",
       "      <td>156</td>\n",
       "      <td>235</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.898265e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342523</th>\n",
       "      <td>20220420</td>\n",
       "      <td>4</td>\n",
       "      <td>45536</td>\n",
       "      <td>2</td>\n",
       "      <td>267</td>\n",
       "      <td>133</td>\n",
       "      <td>204</td>\n",
       "      <td>90</td>\n",
       "      <td>186</td>\n",
       "      <td>162</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.894295e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342550</th>\n",
       "      <td>20220420</td>\n",
       "      <td>4</td>\n",
       "      <td>41354</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>68</td>\n",
       "      <td>167</td>\n",
       "      <td>90</td>\n",
       "      <td>93</td>\n",
       "      <td>106</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.907342e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342577</th>\n",
       "      <td>20220420</td>\n",
       "      <td>4</td>\n",
       "      <td>45539</td>\n",
       "      <td>2</td>\n",
       "      <td>-6</td>\n",
       "      <td>88</td>\n",
       "      <td>127</td>\n",
       "      <td>90</td>\n",
       "      <td>-46</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.924889e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows  32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Calendar_date  route_id  bus_id  stop_sequence  arrival_delay  \\\n",
       "3186         20220110         4   44410              1             49   \n",
       "3213         20220110         4   41370              1             65   \n",
       "3240         20220110         4   41353              1             23   \n",
       "3267         20220110         4   44413              1             72   \n",
       "3294         20220110         4   45544              1            182   \n",
       "...               ...       ...     ...            ...            ...   \n",
       "342469       20220420         4   44059              2            109   \n",
       "342496       20220420         4   44066              2            242   \n",
       "342523       20220420         4   45536              2            267   \n",
       "342550       20220420         4   41354              2            130   \n",
       "342577       20220420         4   45539              2             -6   \n",
       "\n",
       "        dwell_time  travel_time_for_previous_section  scheduled_travel_time  \\\n",
       "3186             0                                 0                    120   \n",
       "3213             0                                 0                    120   \n",
       "3240             0                                 0                    120   \n",
       "3267             0                                 0                    120   \n",
       "3294             0                                 0                    120   \n",
       "...            ...                               ...                    ...   \n",
       "342469          83                               153                     90   \n",
       "342496         119                               101                     90   \n",
       "342523         133                               204                     90   \n",
       "342550          68                               167                     90   \n",
       "342577          88                               127                     90   \n",
       "\n",
       "        upstream_stop_delay  origin_delay  ...  factor(weather)Snow  \\\n",
       "3186                      8             8  ...                    0   \n",
       "3213                     47            47  ...                    0   \n",
       "3240                     19            19  ...                    0   \n",
       "3267                     39            39  ...                    0   \n",
       "3294                    144           144  ...                    0   \n",
       "...                     ...           ...  ...                  ...   \n",
       "342469                   60            87  ...                    0   \n",
       "342496                  156           235  ...                    0   \n",
       "342523                  186           162  ...                    0   \n",
       "342550                   93           106  ...                    0   \n",
       "342577                  -46             7  ...                    0   \n",
       "\n",
       "        factor(temperature)Cold  factor(temperature)Extra_cold  \\\n",
       "3186                          1                              0   \n",
       "3213                          1                              0   \n",
       "3240                          1                              0   \n",
       "3267                          1                              0   \n",
       "3294                          1                              0   \n",
       "...                         ...                            ...   \n",
       "342469                        0                              0   \n",
       "342496                        0                              0   \n",
       "342523                        0                              0   \n",
       "342550                        0                              0   \n",
       "342577                        0                              0   \n",
       "\n",
       "        factor(temperature)Normal factor(day_of_week)weekday  \\\n",
       "3186                            0                          1   \n",
       "3213                            0                          1   \n",
       "3240                            0                          1   \n",
       "3267                            0                          1   \n",
       "3294                            0                          1   \n",
       "...                           ...                        ...   \n",
       "342469                          1                          1   \n",
       "342496                          1                          1   \n",
       "342523                          1                          1   \n",
       "342550                          1                          1   \n",
       "342577                          1                          1   \n",
       "\n",
       "       factor(day_of_week)weekend factor(time_of_day)Afternoon_peak  \\\n",
       "3186                            0                                 0   \n",
       "3213                            0                                 0   \n",
       "3240                            0                                 0   \n",
       "3267                            0                                 0   \n",
       "3294                            0                                 0   \n",
       "...                           ...                               ...   \n",
       "342469                          0                                 1   \n",
       "342496                          0                                 1   \n",
       "342523                          0                                 1   \n",
       "342550                          0                                 1   \n",
       "342577                          0                                 1   \n",
       "\n",
       "       factor(time_of_day)Morning_peak  factor(time_of_day)Off-peak  \\\n",
       "3186                                 1                            0   \n",
       "3213                                 1                            0   \n",
       "3240                                 1                            0   \n",
       "3267                                 1                            0   \n",
       "3294                                 1                            0   \n",
       "...                                ...                          ...   \n",
       "342469                               0                            0   \n",
       "342496                               0                            0   \n",
       "342523                               0                            0   \n",
       "342550                               0                            0   \n",
       "342577                               0                            0   \n",
       "\n",
       "        predicted_delay  \n",
       "3186       1.267187e+08  \n",
       "3213       1.267306e+08  \n",
       "3240       1.267272e+08  \n",
       "3267       1.267221e+08  \n",
       "3294       1.267323e+08  \n",
       "...                 ...  \n",
       "342469    -3.911516e+06  \n",
       "342496    -3.898265e+06  \n",
       "342523    -3.894295e+06  \n",
       "342550    -3.907342e+06  \n",
       "342577    -3.924889e+06  \n",
       "\n",
       "[30000 rows x 32 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.head(30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5abbbf21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: -287821276658.2489\n",
      "MAE: 45913565.2692\n"
     ]
    }
   ],
   "source": [
    "# Extracting the actual and predicted values from the DataFrame\n",
    "actual_values = pred[\"arrival_delay\"].values\n",
    "predicted_values = pred[\"predicted_delay\"].values\n",
    "\n",
    "# Computing R^2\n",
    "r2 = r2_score(actual_values, predicted_values)\n",
    "\n",
    "# Computing MAE\n",
    "mae = mean_absolute_error(actual_values, predicted_values)\n",
    "\n",
    "print(f\"R^2: {r2:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122ca603",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fba125be",
   "metadata": {},
   "source": [
    "# NN VS LR (Day type onlye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a874fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_day_based_model(df, n_folds=5):\n",
    "    df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "    results = {\n",
    "        'day_type': [],\n",
    "        'best_model': [],\n",
    "        'R^2': [],\n",
    "        'MAE': []\n",
    "    }\n",
    "\n",
    "    for day_type in ['weekday', 'weekend']:\n",
    "        print(f\"Processing for {day_type}...\")\n",
    "            \n",
    "        df_train_subset = df_train[df_train['day_of_week'] == day_type]\n",
    "        df_test_subset = df_test[df_test['day_of_week'] == day_type]\n",
    "\n",
    "        drop_columns = ['arrival_delay', 'day_of_week', 'time_of_day', \"weather\", \"temperature\"]\n",
    "        x_train = df_train_subset.drop(columns=drop_columns, errors='ignore').astype('float32')\n",
    "        y_train = df_train_subset['arrival_delay'].astype('float32')\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        x_train_normalized = scaler.fit_transform(x_train)\n",
    "\n",
    "        r2_scores_nn = []\n",
    "        r2_scores_lr = []\n",
    "        maes_nn = []\n",
    "        maes_lr = []\n",
    "\n",
    "        kf = KFold(n_splits=n_folds)\n",
    "        for fold, (train_index, val_index) in enumerate(kf.split(x_train_normalized)):\n",
    "            print(f\"Running Fold {fold + 1}...\")\n",
    "\n",
    "            x_train_fold, x_val_fold = x_train_normalized[train_index], x_train_normalized[val_index]\n",
    "            y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "            # Neural Network\n",
    "            print(\"Training Neural Network...\")\n",
    "            model_nn = Sequential([\n",
    "                Dense(64, activation='relu', input_dim=x_train_fold.shape[1]),\n",
    "                Dense(32, activation='relu'),\n",
    "                Dense(16, activation='relu'),\n",
    "                Dense(1)\n",
    "            ])\n",
    "            model_nn.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "            early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "            model_nn.fit(x_train_fold, y_train_fold, validation_data=(x_val_fold, y_val_fold), epochs=100, batch_size=16, callbacks=[early_stopping], verbose=0)\n",
    "            y_pred_nn = model_nn.predict(x_val_fold).flatten()\n",
    "            r2_scores_nn.append(r2_score(y_val_fold, y_pred_nn))\n",
    "            maes_nn.append(mean_absolute_error(y_val_fold, y_pred_nn))\n",
    "\n",
    "            # Linear Regression\n",
    "            print(\"Training Linear Regression...\")\n",
    "            model_lr = LinearRegression().fit(x_train_fold, y_train_fold)\n",
    "            y_pred_lr = model_lr.predict(x_val_fold)\n",
    "            r2_scores_lr.append(r2_score(y_val_fold, y_pred_lr))\n",
    "            maes_lr.append(mean_absolute_error(y_val_fold, y_pred_lr))\n",
    "\n",
    "        avg_mae_nn = np.mean(maes_nn)\n",
    "        avg_mae_lr = np.mean(maes_lr)\n",
    "        if avg_mae_nn < avg_mae_lr:\n",
    "            best_model = \"NN\"\n",
    "            best_r2 = np.mean(r2_scores_nn)\n",
    "            best_mae = avg_mae_nn\n",
    "            if not os.path.exists(\"models_day\"):\n",
    "                os.makedirs(\"models_day\")\n",
    "            model_nn.save(os.path.join(\"models_day\", f'nn_model_{day_type}.h5'))\n",
    "        else:\n",
    "            best_model = \"LR\"\n",
    "            best_r2 = np.mean(r2_scores_lr)\n",
    "            best_mae = avg_mae_lr\n",
    "            if not os.path.exists(\"models_day\"):\n",
    "                os.makedirs(\"models_day\")\n",
    "            joblib.dump(model_lr, os.path.join(\"models_day\", f'lr_model_{day_type}.pkl'))\n",
    "\n",
    "        results['day_type'].append(day_type)\n",
    "        results['best_model'].append(best_model)\n",
    "        results['R^2'].append(best_r2)\n",
    "        results['MAE'].append(best_mae)\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def predict_day_based_data(df):\n",
    "    all_groups = []\n",
    "\n",
    "    grouped = df.groupby(['day_of_week'])\n",
    "    for day_type, group in grouped:\n",
    "        nn_model_path = os.path.join(\"models_day\", f'nn_model_{day_type}.h5')\n",
    "        lr_model_path = os.path.join(\"models_day\", f'lr_model_{day_type}.pkl')\n",
    "\n",
    "        X = group.drop(columns=['arrival_delay', 'day_of_week', 'time_of_day', \"weather\", \"temperature\"], errors='ignore').astype('float32')\n",
    "        \n",
    "        if os.path.exists(nn_model_path):\n",
    "            model = load_model(nn_model_path)\n",
    "            group['predicted_delay'] = model.predict(X).flatten()\n",
    "        elif os.path.exists(lr_model_path):\n",
    "            model = joblib.load(lr_model_path)\n",
    "            group['predicted_delay'] = model.predict(X)\n",
    "        else:\n",
    "            raise ValueError(f\"No saved model found for day_type: {day_type}\")\n",
    "\n",
    "        all_groups.append(group)\n",
    "\n",
    "    result_df = pd.concat(all_groups)\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b6172e",
   "metadata": {},
   "source": [
    "### Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73215be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_day = train_evaluate_day_based_model(df)\n",
    "print(results_df_day)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a860c88f",
   "metadata": {},
   "source": [
    "### USING the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9948097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predict_day_based_data(df)\n",
    "pred.head()\n",
    "# Extracting the actual and predicted values from the DataFrame\n",
    "actual_values = pred[\"arrival_delay\"].values\n",
    "predicted_values = pred[\"predicted_delay\"].values\n",
    "\n",
    "# Computing R^2\n",
    "r2 = r2_score(actual_values, predicted_values)\n",
    "\n",
    "# Computing MAE\n",
    "mae = mean_absolute_error(actual_values, predicted_values)\n",
    "\n",
    "print(f\"R^2: {r2:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
